{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandasql import sqldf\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from finance_byu.fama_macbeth import fama_macbeth, fm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRSP = pd.read_sas('crsp.sas7bdat', encoding='latin-1') #fp3v1\n",
    "COMP = pd.read_sas('comp.sas7bdat', encoding='latin-1') #fp3v2\n",
    "FF4 = pd.read_sas('ff4data.sas7bdat', encoding='latin-1')\n",
    "COMP_ANNUAL = pd.read_sas('comp_annual.sas7bdat', encoding='latin-1') # fp3v3\n",
    "INDUSTRY =  pd.read_csv('industries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zero(df, var):\n",
    "    temp = df[var].isna().sum()\n",
    "    df[var].fillna(0, inplace=True)\n",
    "    print(\"NAN values for \" + str(var) + \": \" + str(temp))\n",
    "    temp = df[var].isna().sum()\n",
    "    print(\"NAN values for \" + str(var) + \" filled: \" + str(temp) + \" remaining\")\n",
    "\n",
    "def calculate_credit_metrics(compustat_data):\n",
    "    credit_metrics_df = pd.DataFrame()\n",
    "\n",
    "    # Rename \n",
    "    credit_metrics_df[\"Total_Assets\"] = compustat_data[\"AT\"]\n",
    "    credit_metrics_df[\"Current_Liabilities\"] = compustat_data[\"LCO\"]\n",
    "    credit_metrics_df[\"Long_Term_Debt\"] = compustat_data[\"DLTT\"]\n",
    "    credit_metrics_df[\"Total_Liabilities\"] = compustat_data[\"LT\"]\n",
    "    credit_metrics_df[\"Preferred_Stock\"] = compustat_data[\"PSTK\"]\n",
    "    credit_metrics_df[\"Interest_Expense\"] = compustat_data[\"XINT\"]\n",
    "    credit_metrics_df[\"Cash_Short_Term_Investments\"] = compustat_data[\"CHE\"]\n",
    "    credit_metrics_df[\"Net_Income\"] = compustat_data[\"NI\"]\n",
    "    credit_metrics_df[\"Inventory\"] = compustat_data[\"INVT\"]\n",
    "    credit_metrics_df[\"Total_Equity\"] = compustat_data[\"CEQ\"]\n",
    "\n",
    "    # Calculate financial ratios\n",
    "    credit_metrics_df[\"Debt_Equity_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Debt_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Current_Ratio\"] = credit_metrics_df[\"Current_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Quick_Ratio\"] = (credit_metrics_df[\"Current_Liabilities\"] - credit_metrics_df[\"Inventory\"]) / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Interest_Coverage_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Interest_Expense\"]\n",
    "    credit_metrics_df[\"Return_On_Assets\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Return_On_Equity\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Asset_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Inventory_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Inventory\"]\n",
    "\n",
    "    return credit_metrics_df\n",
    "\n",
    "def calculate_credit_score(credit_metrics_df):\n",
    "    # Define weights for each financial metric\n",
    "    weights = {\n",
    "        \"Debt_Equity_Ratio\": 0.2,\n",
    "        \"Debt_Ratio\": 0.1,\n",
    "        \"Current_Ratio\": 0.1,\n",
    "        \"Quick_Ratio\": 0.1,\n",
    "        \"Interest_Coverage_Ratio\": 0.1,\n",
    "        \"Return_On_Assets\": 0.1,\n",
    "        \"Return_On_Equity\": 0.1,\n",
    "        \"Asset_Turnover_Ratio\": 0.1,\n",
    "        \"Inventory_Turnover_Ratio\": 0.1\n",
    "    }\n",
    "\n",
    "    # Calculate the weighted sum of normalized metrics\n",
    "    credit_score = (credit_metrics_df * pd.Series(weights)).sum(axis=1)\n",
    "\n",
    "    return credit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factors:\n",
    "  @staticmethod\n",
    "  def _create_hedge_portfolio(data: pd.DataFrame, factor_col: str, q=10, direction=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a hedge portfolio, using D10 - D1 returns by default.\n",
    "\n",
    "    Args:\n",
    "      data (pd.DataFrame): Data, must contain columns ['monthid', 'RET', factor_col]\n",
    "      factor_col (str): Name of factor column, i.e. ep1\n",
    "      q (int, optional): Defaults to deciles (10).\n",
    "      direction (int, optional): Either 1 or -1. If 1, we do High - Low. Otherwise, Low - High.\n",
    "\n",
    "    Returns: Return of hedge portfolio at each monthid (i.e. the factor)\n",
    "    \"\"\"\n",
    "    factor = []\n",
    "    index = []  # monthid - 1\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp[factor_col].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    for monthid, mdata in mth_grp:\n",
    "      # TODO: can add value weighting of returns here if anyone needs it\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == q-1]['RET'].mean()\n",
    "      factor.append(direction * (d10 - d1))\n",
    "      index.append(monthid - 1)\n",
    "    return pd.DataFrame(factor, index=index)\n",
    "  \n",
    "  @staticmethod\n",
    "  def dNoa(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    # annual_data = COMP_ANNUAL\n",
    "    fill_zero(annual_data, 'DLC')\n",
    "    fill_zero(annual_data, 'DLTT')\n",
    "    fill_zero(annual_data, 'MIB')\n",
    "    fill_zero(annual_data, 'PSTK')\n",
    "\n",
    "    operating_assets = annual_data[\"AT\"] - annual_data[\"CHE\"]\n",
    "    operating_liabilities = annual_data[\"AT\"] - annual_data[\"DLC\"] - annual_data[\"DLTT\"] - annual_data[\"MIB\"] - annual_data[\"PSTK\"] - annual_data[\"CEQ\"]\n",
    "\n",
    "    Noa = operating_assets - operating_liabilities\n",
    "\n",
    "    lagged_total_assets = annual_data[\"AT\"].shift(1)  # 1-year-lagged total assets\n",
    "    dNoa = (Noa - Noa.shift(1)) / lagged_total_assets\n",
    "\n",
    "    annual_data[\"dNoa\"] = dNoa\n",
    "    annual_data[\"dNoa\"].fillna(0, inplace=True)\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNoa \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNoa'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def Nsi(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "\n",
    "    annual_data[\"CSHO_t_minus_1_adjusted\"] = annual_data[\"CSHO\"] * annual_data[\"AJEX\"]\n",
    "\n",
    "    test_shifted = annual_data.shift(periods=1)\n",
    "    annual_data[\"CSHO_t_minus_2_adjusted\"] = test_shifted[\"CSHO\"] * test_shifted[\"AJEX\"]\n",
    "\n",
    "    annual_data[\"Nsi_u\"] = np.log(annual_data[\"CSHO_t_minus_1_adjusted\"] / annual_data[\"CSHO_t_minus_2_adjusted\"])\n",
    "    annual_data[\"Nsi_u\"].fillna(0, inplace=True)\n",
    "\n",
    "    annual_data[\"Nsi\"] = np.where(annual_data[\"Nsi_u\"] < 0, np.where(annual_data[\"Nsi_u\"] < annual_data[\"Nsi_u\"].quantile(0.5), 1, 2),\n",
    "                             np.where(annual_data[\"Nsi_u\"] == 0, 3,\n",
    "                                      np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.1), 4,\n",
    "                                               np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.2), 5,\n",
    "                                                        np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.3), 6,\n",
    "                                                                 np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.4), 7,\n",
    "                                                                          np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.5), 8,\n",
    "                                                                                   np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.6), 9, 10))))))))\n",
    "    annual_data[\"Nsi\"]\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.Nsi \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Nsi'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dNca(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"IVAO\")\n",
    "\n",
    "    annual_data[\"Nca\"] = annual_data[\"AT\"] - annual_data[\"ACT\"] - annual_data[\"IVAO\"]\n",
    "    annual_data[\"dNca_o\"] = annual_data[\"Nca\"].diff()\n",
    "    annual_data[\"dNca_o\"].fillna(0, inplace=True)\n",
    "\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dNca\"] = annual_data[\"dNca_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dFnl(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"DLTT\")\n",
    "    fill_zero(annual_data, \"DLC\")\n",
    "    fill_zero(annual_data, \"PSTK\")\n",
    "\n",
    "    annual_data[\"Fnl\"] = annual_data[\"DLTT\"] + annual_data[\"DLC\"] + annual_data[\"PSTK\"]\n",
    "    annual_data[\"dFnl_o\"] = annual_data[\"Fnl\"].diff()\n",
    "    annual_data[\"dFnl_o\"].fillna(0, inplace=True)\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dFnl\"] = annual_data[\"dFnl_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dFnl \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dFnl'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def creditrisk(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    credit_metrics = calculate_credit_metrics(annual_data)\n",
    "    credit_score = calculate_credit_score(credit_metrics)\n",
    "    annual_data[\"cdrk\"] = credit_score\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.cdrk \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['cdrk'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def epq1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data = data[data['IBQ'] >= 0]\n",
    "    data['Epq1'] = data['IBQ'] * 1000000 / data['MKTCAP']\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Epq1'].transform(lambda x: pd.qcut(x, 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d1 - d10)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ioca(data):\n",
    "    CPI = pd.read_csv('cpi.csv')\n",
    "    g = .10\n",
    "    d = .15\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data = pd.merge(annual_data, CPI, on='year')\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    grouped = annual_data.groupby('LPERMNO')\n",
    "    oc = []\n",
    "    for _, grp in grouped:\n",
    "      prev = None\n",
    "      for _, row in grp.iterrows():\n",
    "        if prev == None:\n",
    "          prev = row['XSGA'] / (g+d)\n",
    "        else:\n",
    "          prev = (1 - d) * prev + row['XSGA'] / row['CPI']\n",
    "        oc.append(prev)\n",
    "    annual_data['oc'] = oc\n",
    "    annual_data = annual_data[(annual_data['oc'] > 0) & (annual_data['AT'] > 0)]\n",
    "    annual_data['oca'] = annual_data['oc'] / annual_data['AT']\n",
    "    def yearly_winsorize(srs):\n",
    "      p1, p99 = np.nanpercentile(srs, [1, 99])\n",
    "      return np.clip(srs, p1, p99)\n",
    "    annual_data['ioca'] = annual_data.groupby('year')['oca'].transform(yearly_winsorize)\n",
    "    annual_data['ioca'] = annual_data.groupby('industry')['ioca'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "    data = sqldf(\"SELECT a.*, b.ioca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['ioca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ra26(data):\n",
    "    factor = []\n",
    "    data = data.sort_values(['PERMNO','monthid'])\n",
    "    datagrp = data.groupby('PERMNO')\n",
    "    for _, grp in datagrp:\n",
    "      for mid in grp['monthid']:\n",
    "        tm = grp[grp['monthid'].isin([mid - 24, mid - 36, mid - 48, mid - 60])]\n",
    "        if (len(tm) < 4):\n",
    "          factor.append(np.NaN)\n",
    "        else:\n",
    "          factor.append(tm['RET'].mean())\n",
    "    data['ra26'] = factor\n",
    "    return Factors._create_hedge_portfolio(data, 'ra26')\n",
    "\n",
    "  @staticmethod\n",
    "  def Abr1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "\n",
    "    # RET_DAILY = pd.read_sas('ret_daily.sas7bdat', encoding='latin-1')  sas is SLOW\n",
    "    ret_daily = pd.read_parquet(\"ret_daily.parquet\")\n",
    "    vwret = pd.read_sas('us_vwret.sas7bdat', encoding='latin-1').set_index(\"date\")\n",
    "\n",
    "    ret_daily[\"monthid\"] = (ret_daily.DATE.dt.year-1975)*12 + ret_daily.DATE.dt.month\n",
    "\n",
    "    stock_returns = ret_daily.set_index([\"PERMNO\", \"DATE\"]).sort_index()\n",
    "    del ret_daily  # save memory\n",
    "    # faster to pivot first and then do the operations, rather than doing a groupby\n",
    "    stock_returns = stock_returns.pivot_table(values=\"RET\", columns=\"PERMNO\", index=\"DATE\")\n",
    "    stock_returns = stock_returns.sub(vwret.VWRETD, axis=0)  # return over market\n",
    "\n",
    "    # get all 4-period returns from T-3 to T+1\n",
    "    stock_returns = stock_returns.rolling(4).sum().shift(-1)\n",
    "    stock_returns = pd.DataFrame(stock_returns.stack())\n",
    "    stock_returns = stock_returns.rename(columns={0:\"Abr\"})\n",
    "\n",
    "    # Merge on RDQ date so we only have the returns around earnings date\n",
    "    rdqs = data[[\"PERMNO\", \"RDQ\"]].dropna()\n",
    "    rdqs.RDQ = pd.to_datetime(rdqs.RDQ)\n",
    "    rdqs = rdqs.drop_duplicates()\n",
    "    rdqs = rdqs.merge(stock_returns, left_on=[\"RDQ\", \"PERMNO\"], right_index=True, how=\"left\")\n",
    "    del stock_returns  # save memory\n",
    "    # This is the date we use to calculate the monthid to avoid lookahead bias,\n",
    "    # since Abr is calculated using RDQ-3 to RDQ+1 returns.\n",
    "    rdqs[\"RDQ+1\"] = rdqs.RDQ + pd.offsets.BDay(1)\n",
    "    rdqs[\"monthid\"] = (rdqs[\"RDQ+1\"].dt.year-1975)*12 + rdqs[\"RDQ+1\"].dt.month\n",
    "\n",
    "    rdqs = rdqs.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # duplicates can occur where RDQ is in the same month. We drop the first month-PERMNO duplicate\n",
    "    rdqs = rdqs[~rdqs.index.duplicated(keep=\"last\")]\n",
    "\n",
    "    final = pd.DataFrame(index=data.set_index([\"PERMNO\", \"monthid\"]).index).sort_index()\n",
    "    final[\"Abr1\"] = rdqs.Abr\n",
    "    # forward fill only 6 months to avoid stale data\n",
    "    # TODO: could possibly be problems if data skips some monthids, but we still have no lookahead bias, just possible stale data\n",
    "    final = final.groupby(level=0).ffill(limit=6)\n",
    "\n",
    "    data = data.merge(final, how=\"left\", left_on=[\"PERMNO\", \"monthid\"], right_index=True).sort_values(by=['PERMNO', 'monthid'])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"Abr1\", q=10, direction=1)\n",
    "    # return data\n",
    "\n",
    "  @staticmethod\n",
    "  def e11(data):\n",
    "    \"\"\"\n",
    "    Calculate Îµ11 factor (Residual momentum, prior 11-month returns) with 1 month holding period.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Get a series of rf indexed by date\n",
    "    rf = data.set_index(\"monthid\")[[\"RF\"]].reset_index().drop_duplicates(subset=\"monthid\")\n",
    "    rf = rf.set_index(\"monthid\").sort_index().RF\n",
    "\n",
    "    # Get xret with each permno in a column\n",
    "    xret = data.loc[:,~data.columns.duplicated()].pivot_table(index=\"monthid\", columns=\"PERMNO\", values=\"RET\").sort_index()\n",
    "    xret = xret.sub(rf, axis=0)\n",
    "\n",
    "    # Get ff data with constant\n",
    "    ff_3 = data[[\"monthid\", \"SMB\", \"HML\", \"MKTRF\"]].drop_duplicates(subset=\"monthid\").set_index(\"monthid\").sort_index()\n",
    "    ff_3 = sm.add_constant(ff_3)\n",
    "\n",
    "    from numpy.linalg import pinv\n",
    "\n",
    "    def last_ff_residual(series: pd.Series, ff: pd.DataFrame) -> float:\n",
    "      \"\"\"Computes FF residuals for a series of excess returns.\n",
    "\n",
    "      Args:\n",
    "        series (pd.DataFrame): rolling excess returns. Must have no null values.\n",
    "        ff (pd.DataFrame): factors, must have overlapping index with `series`. All columns are used as factors. Must have constant column added.\n",
    "\n",
    "      Returns: residual on last date T\n",
    "      \"\"\"\n",
    "      # y = series\n",
    "      x = ff.loc[series.index]\n",
    "      \n",
    "      # ffmodel = sm.OLS(y, x).fit()\n",
    "      # residual_values = ffmodel.resid\n",
    "\n",
    "      # sm.OLS is too slow, do it with linear algebra instead\n",
    "      params = pinv(x).dot(series)\n",
    "\n",
    "      # calculate last residual\n",
    "      t_residual = series.iloc[-1] - x.iloc[-1].dot(params)\n",
    "      \n",
    "      return t_residual\n",
    "\n",
    "    residuals = xret.rolling(window=36, min_periods=36).apply(\n",
    "      lambda series: last_ff_residual(series, ff_3)\n",
    "    )\n",
    "    scaled_residuals = residuals / residuals.rolling(36, min_periods=12).std()\n",
    "\n",
    "    # The time T residual momentum is the sum of residual returns for T-12, T-11, ... T-1\n",
    "    # We do this with a rolling 11 period sum, and then shift down by 1\n",
    "    e11 = scaled_residuals.rolling(11).sum().shift()\n",
    "\n",
    "    # Reshape so the columns are [monthid, PERMNO, e11] and merge into data\n",
    "    e11 = pd.DataFrame(e11.stack()).rename(columns={0: \"e11\"})\n",
    "    data = data.merge(e11, how=\"left\", left_on=[\"monthid\", \"PERMNO\"], right_index=True)\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"e11\", q=10, direction=1)\n",
    "\n",
    "  @staticmethod\n",
    "  def Re1(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    ibes_link = pd.read_csv(\"crsp_ibes_link.csv\")  # ibes ticker to PERMNO map  https://wrds-www.wharton.upenn.edu/pages/get-data/linking-suite-wrds/ibes-crsp-link/\n",
    "    ibes_eps = pd.read_csv(\"ibes_eps_estimate.csv\")  # Mean EPS estimates  https://wrds-www.wharton.upenn.edu/pages/get-data/ibes-thomson-reuters/ibes-academic/summary-history/summary-statistics/\n",
    "\n",
    "    ibes_link = ibes_link.dropna()\n",
    "\n",
    "    # Only want USD currency\n",
    "    ibes_eps = ibes_eps[ibes_eps.CURCODE == \"USD\"]\n",
    "\n",
    "    # Get the estimates with the date and permno\n",
    "    eps_est = sqldf(\n",
    "      \"\"\"\n",
    "      select l.permno, e.STATPERS as DATE, e.MEANEST\n",
    "      from ibes_eps e\n",
    "      left join ibes_link l\n",
    "      on e.ticker = l.TICKER and e.STATPERS >= l.sdate and e.STATPERS <= l.edate \n",
    "      \"\"\"\n",
    "    )\n",
    "\n",
    "    # Add monthid\n",
    "    eps_est = eps_est.drop_duplicates(subset=[\"DATE\", \"PERMNO\"])\n",
    "    eps_est.DATE = pd.to_datetime(eps_est.DATE)\n",
    "    eps_est['monthid'] = (eps_est.DATE.dt.year-1975)*12 + eps_est.DATE.dt.month\n",
    "\n",
    "    # Merge close price\n",
    "    eps_est = eps_est.merge(data.set_index([\"monthid\", \"PERMNO\"]).PRC, on=[\"monthid\", \"PERMNO\"])\n",
    "    eps_est = eps_est.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # Calculate factor value for each stock\n",
    "\n",
    "    # TODO: we should make PRC the split adjusted price as our EPS values are split adjusted\n",
    "    re = eps_est.reset_index().set_index(\"monthid\").sort_index().groupby([\"PERMNO\"]).apply(\n",
    "        # 6 period rolling sum of (f_t - f_t-1) / p_t-1, requiring at least 4 consecutive observations\n",
    "        lambda df: ((df.MEANEST - df.MEANEST.shift()) / df.PRC.shift()).rolling(window=6, min_periods=4).sum()\n",
    "    )\n",
    "    eps_est[\"Re1\"] = re\n",
    "    \n",
    "    data = data.merge(eps_est[[\"Re1\"]], how=\"left\", on=[\"monthid\", \"PERMNO\"])\n",
    "    \n",
    "    return Factors._create_hedge_portfolio(data, \"Re1\", q=10, direction=1)\n",
    "  \n",
    "\n",
    "  # D. Investment ==========================================\n",
    "  @staticmethod \n",
    "  def _compute_shifted(data, factor_col, input_col1, input_col2, shift_amt, op='-'):\n",
    "    \"\"\"\n",
    "    for factor calculations that require a shift of data values to avoid\n",
    "    lookahead bias:\n",
    "    Input:\n",
    "      data: DataFrame\n",
    "      factor_col: name of factor to be computed\n",
    "      input_col: name of column used in the factor computation\n",
    "      shift_amt: number of months to lag by for input_col\n",
    "    Return:\n",
    "      a dataframe with cols ['monthid', 'PERMNO', 'factor'] for merge\n",
    "      into the overall data\n",
    "    \"\"\"\n",
    "    permno_grp = data.groupby('PERMNO')\n",
    "    # construct a mini dataframe of shifted values -> (monthid, permno, dRoa1 computed for the relevant month)\n",
    "    factor_values = {'monthid': [], 'PERMNO': [], factor_col:[]}\n",
    "\n",
    "    for _, pdata in permno_grp:\n",
    "      # sort by monthid\n",
    "      pdata = pdata.sort_values('monthid') \n",
    "      # lag Roa to avoid lookahead bias\n",
    "      if (op == '-'):\n",
    "        pdata[factor_col] = pdata[input_col1] - pdata[input_col2].shift(shift_amt)\n",
    "      else:\n",
    "        pdata[factor_col] = pdata[input_col1] / pdata[input_col2].shift(shift_amt)\n",
    "      # add to dataframe\n",
    "      \n",
    "      factor_values['PERMNO'].extend(pdata['PERMNO'].tolist())\n",
    "      factor_values['monthid'].extend(pdata['monthid'].tolist())\n",
    "      factor_values[factor_col].extend(pdata[factor_col].tolist())\n",
    "\n",
    "    factor_values = pd.DataFrame(factor_values)\n",
    "    factor_values['monthid'] = factor_values['monthid'].astype(np.int64)\n",
    "    factor_values['PERMNO'] = factor_values['PERMNO'].astype(np.int64)\n",
    "\n",
    "    return pd.DataFrame(factor_values)\n",
    "    \n",
    "  @staticmethod\n",
    "  def droe1(data):\n",
    "    \"\"\"dRoe: return on equity minus its value from four quarters ago \"\"\"\n",
    "    #   for each month t, sort all stocks into deciles based on their most recent past dRoe\n",
    "    #   monthly decile returns calculated for the current month t\n",
    "\n",
    "    # ROE = NET (RDQ) / Equity (CEQQ)   \n",
    "    data = data.copy()\n",
    "    data['Roe'] = data['NIQ'] / data['CEQQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoe1', input_col1='Roe', input_col2='Roe', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoe1\", q=10)\n",
    "  \n",
    "  @staticmethod\n",
    "  def droa1(data):\n",
    "    \"\"\" droa1 \"is return on assets minus its value from four quarters ago\" \"\"\"\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data['Roa'] = data['NIQ'] / data['ATQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoa1', input_col1='Roa', input_col2='Roa', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoa1\", q=10)\n",
    "\n",
    "  @staticmethod\n",
    "  def rnaq1(data):\n",
    "    \"\"\" Rnaq1: Quarterly return on net operating assets \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='rnaq1', input_col1='OIADPQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'rnaq1')\n",
    "\n",
    "  @staticmethod\n",
    "  def atoq1(data):\n",
    "    \"\"\" atoq1: quarterly sales divided by 1-quarter-lagged Noa \"\"\"\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='atoq1', input_col1='SALEQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'atoq1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assets:\n",
    "  crsp = CRSP.copy()\n",
    "  comp = COMP.copy()\n",
    "  ff4 = FF4.copy()\n",
    "  fact = pd.DataFrame()\n",
    "  data = pd.DataFrame()\n",
    "  train_start = '1975-01-01'\n",
    "  train_end = '2005-12-31'\n",
    "  # test_start = '2006-01-01'\n",
    "  # test_end = '2020-12-31'\n",
    "  factors = {\n",
    "    'epq1': Factors.epq1,\n",
    "    # 'ioca': Factors.ioca,\n",
    "    # 'ra26': Factors.ra26,\n",
    "    # 'e11': Factors.e11,  # comment out for now as this takes ~12min to run\n",
    "    # 'Re1': Factors.Re1,\n",
    "    # 'Abr1': Factors.Abr1,\n",
    "\n",
    "    # D. Investment =====================================\n",
    "    # 'dRoe1': Factors.droe1,\n",
    "    # 'dRoa1': Factors.droa1,\n",
    "    # 'rnaq1': Factors.rnaq1,\n",
    "    # 'atoq1': Factors.atoq1,\n",
    "\n",
    "    # 'dNoa': Factors.dNoa,\n",
    "    # 'Nsi': Factors.Nsi,\n",
    "    # 'dNca': Factors.dNca,\n",
    "    # 'dFnl' : Factors.dFnl\n",
    "    # 'creditrisk': Factors.creditrisk\n",
    "  }\n",
    "  factor_fm = pd.DataFrame(columns=['mean','std_error','tstat'])\n",
    "  \n",
    "  def __init__(self, start_date=None):\n",
    "\n",
    "    # Make testing faster by optiSonally limiting dates\n",
    "    if start_date is not None:\n",
    "      self.crsp = self.crsp[self.crsp.DATE >= start_date]\n",
    "      self.comp = self.comp[self.comp.DATADATE >= start_date]\n",
    "\n",
    "    self.clean_crsp()\n",
    "    self.clean_comp()\n",
    "    self.clean_ff4()\n",
    "    self.illiquidity_filter()\n",
    "    \n",
    "    self.merge_data()\n",
    "    self.gen_factors()\n",
    "    self.fama_macbeth()\n",
    "    \n",
    "  def clean_crsp(self):\n",
    "    self.crsp['PERMNO'] = self.crsp['PERMNO'].astype(int)\n",
    "    self.crsp['year'] = self.crsp['DATE'].dt.year\n",
    "    self.crsp['month'] = self.crsp['DATE'].dt.month\n",
    "    self.crsp['monthid'] = (self.crsp['year']-1975)*12 + self.crsp['month']\n",
    "    self.crsp['PRC'] = self.crsp['PRC'].apply(lambda x: x if x > 0 else x * -1)\n",
    "    \n",
    "  def clean_comp(self):\n",
    "    self.comp['qtrid'] = (self.comp['DATADATE'].dt.year-1975)*12 + self.comp['DATADATE'].dt.month\n",
    "    self.comp['LPERMNO'] = self.comp['LPERMNO'].astype(int)\n",
    "    self.comp.drop(columns=['CONSOL', 'INDFMT', 'DATAFMT', 'POPSRC', 'DATAFQTR', 'DATACQTR', 'CURCDQ', 'COSTAT'], \n",
    "                  inplace=True)\n",
    "    \n",
    "  def clean_ff4(self):\n",
    "    self.ff4['monthid'] = (self.ff4['DATEFF'].dt.year-1975)*12 + self.ff4['DATEFF'].dt.month\n",
    "    self.fact = self.ff4.copy()\n",
    "    \n",
    "  def illiquidity_filter(self):\n",
    "    self.crsp = self.crsp[self.crsp['PRC'] >= 5]\n",
    "    self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n",
    "    tmp = {}\n",
    "    grp = self.crsp[(self.crsp['month'] == 1) & (self.crsp['MKTCAP'] >= 100000000)].groupby('year')\n",
    "    for yr, group in grp:\n",
    "      tmp[yr] = list(group['PERMNO'])\n",
    "    liquidity = self.crsp.groupby(['year'])['PERMNO'].transform(lambda x: x.isin(tmp[x.name]))\n",
    "    self.crsp = self.crsp[liquidity]\n",
    "    \n",
    "  def merge_data(self):\n",
    "    lhs = self.crsp\n",
    "    rhs = self.comp\n",
    "    self.data = sqldf(\"SELECT a.*, b.* \\\n",
    "                       FROM lhs as a \\\n",
    "                       INNER JOIN rhs as b \\\n",
    "                       ON a.PERMNO = b.LPERMNO and a.monthid >= b.qtrid + 4 and a.monthid <= b.qtrid + 6\")\n",
    "    self.data.drop_duplicates(subset=['PERMNO', 'monthid'], keep='last', inplace=True)\n",
    "    self.data = self.data.loc[:,~self.data.columns.duplicated()].copy()  # remove duplicate col\n",
    "    self.data = pd.merge(self.data, self.ff4, on='monthid')\n",
    "  \n",
    "  def gen_factors(self):\n",
    "    for factor, func in self.factors.items():\n",
    "      try:\n",
    "        self.fact[factor] = func(self.data)\n",
    "      except Exception as e:\n",
    "        print(f\"Error generating {factor=}: {e}\")\n",
    "        print(f\"SKIPPING THIS FACTOR\")\n",
    "    self.fact = pd.merge(self.fact, self.data[['monthid','RET','PERMNO']], on='monthid')\n",
    "  \n",
    "  def fama_macbeth(self):\n",
    "    for factor, func in self.factors.items():\n",
    "      try:\n",
    "        fmb = self.fact[['DATEFF','monthid','RET',factor,'SMB','HML','MKTRF','UMD']].copy()\n",
    "        fmb = fmb[(fmb['DATEFF'] >= self.train_start) & (fmb['DATEFF'] <= self.train_end)]\n",
    "        fmb.dropna(inplace=True)\n",
    "        result = fama_macbeth(fmb,'monthid','RET',[factor,'SMB','HML','MKTRF','UMD'],intercept=True)\n",
    "        self.factor_fm.loc[factor] = fm_summary(result).loc[factor]\n",
    "      except Exception as e:\n",
    "        print(f\"Error running Fama Macbeth on {factor=}: {e}\")\n",
    "\n",
    "  def gen_factor_betas(self, train_start='1975-01-01', train_end='2005-12-31'):\n",
    "    \"\"\" \n",
    "      testing sample forecasting for linear models\n",
    "    \"\"\"\n",
    "    # initialize a dictionary to store factor betas, where beta columns\n",
    "    # are named {factor}_b\n",
    "    factor_betas = {'PERMNO':[], 'monthid': [], 'alpha':[]}\n",
    "    factor_cols = []\n",
    "    factor_list = list(self.factors.keys())\n",
    "    for factor in self.factors.keys():\n",
    "      factor_b = factor + \"_b\"\n",
    "      # factor_list.append(factor)\n",
    "      factor_cols.append(factor_b)\n",
    "      factor_betas[factor_b] = []\n",
    "\n",
    "    # get coefficients for factors through regression\n",
    "    # combine by stock first, then regress across times\n",
    "    # TODO rolling 36 months\n",
    "    data = self.fact.copy()\n",
    "\n",
    "    # filter data period\n",
    "    data = data[(data['DATEFF'] >= train_start) & (data['DATEFF'] <= train_end)]\n",
    "    permno_grp = data.groupby('PERMNO')\n",
    "\n",
    "    for permno, pdata in permno_grp:\n",
    "      # dropna TODO consider alternative\n",
    "      pdata = pdata.dropna()\n",
    "      # check number of observations available\n",
    "      if (len(pdata.index) < 12):\n",
    "        continue\n",
    "      # sort by monthid\n",
    "      pdata = pdata.sort_values('monthid') \n",
    "      independents = pdata[factor_list]\n",
    "      # since factors were constructed accounting for lookahead bias (via lags \n",
    "      # when necessary), this step regresses factor values at time t to returns \n",
    "      # at time t\n",
    "      model = linear_model.LinearRegression().fit(independents, pdata[\"RET\"])\n",
    "      # add values to factor coefficients dataframe\n",
    "      factor_betas['PERMNO'].append(pdata['PERMNO'].iloc[0])\n",
    "      factor_betas['monthid'].append(pdata['monthid'].iloc[0])\n",
    "      factor_betas['alpha'].append(model.intercept_)\n",
    "      for i, factor_col in enumerate(factor_cols): \n",
    "        factor_betas[factor_col].append(model.coef_[i])\n",
    "\n",
    "    factor_betas_df = pd.DataFrame(factor_betas)\n",
    "    factor_betas_df.sort_values([\"PERMNO\", \"monthid\"])\n",
    "\n",
    "    return factor_betas_df\n",
    "  \n",
    "  def score_linear(self):\n",
    "    \"\"\" \n",
    "      score stocks during the out of sample period\n",
    "    \"\"\"\n",
    "    # get factor coefficients from regression\n",
    "    data = self.data.copy()\n",
    "    stock_data = self.data.copy()\n",
    "    factor_betas = self.gen_factor_betas()\n",
    "    factor_list = list(self.factors.keys())\n",
    "    data = pd.merge(data, self.fact, on=[\"PERMNO\", \"monthid\"])\n",
    "    data = pd.merge(data, factor_betas, on=[\"PERMNO\", \"monthid\"])\n",
    "\n",
    "    # determine holdings based on ranks - for each time point, have a \n",
    "    # list of permnos for top and lowest deciles \n",
    "\n",
    "    # compute returns based on the given formula\n",
    "    data['pre_ret'] = data['alpha']\n",
    "    data['pre_ret'] = data['pre_ret'].fillna(0)\n",
    "    for factor in factor_list:\n",
    "      factor_b = factor+\"_b\"\n",
    "      data['pre_ret'] = data['pre_ret'] + (data[factor] * data[factor_b])\n",
    "    \n",
    "    # rank stocks for each out-of-sample period and thus rebalance at each time\n",
    "    # we want to use the previous month to predict the next, thus use predicted return\n",
    "    # at t-1 for time t's portfolio construction\n",
    "    grouped_data = []\n",
    "    permno_group = data.groupby('PERMNO')\n",
    "    for _, pdata in permno_group:\n",
    "      # sort by monthid, then shift to get t-1 return\n",
    "      pdata = pdata.sort_values([\"monthid\"])\n",
    "      pdata['pre_ret_t1'] = pdata['pre_ret'] # TODO issue here\n",
    "      # pdata['pre_ret_t1'] = pdata['pre_ret'].shift(1)\n",
    "      grouped_data.append(pdata)\n",
    "    # merge back into overall data \n",
    "    data = pd.concat(grouped_data)\n",
    "\n",
    "    # store what permnos to construct the long / short portfolio with \n",
    "    # initialize a dataframe to track decile 10 and 1 portfolios\n",
    "    # rank stocks to deciles based on the values calculated from the predication equation\n",
    "    data['rank'] = data['pre_ret_t1'].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    decile_permnos = {'monthid': [], 'd1_permnos':[],  'd10_permnos': []}\n",
    "\n",
    "    mth_group = data.groupby('monthid')\n",
    "    for month, mdata in mth_group:\n",
    "      # skipping ones with very little data\n",
    "      if (len(mdata['pre_ret_t1']) < 12):\n",
    "        continue\n",
    "      # construct equal weighted decile portfolios\n",
    "      decile_permnos['monthid'].append(mdata['monthid'].iloc[0])\n",
    "      decile_permnos['d1_permnos'].append(mdata[mdata['rank']==0]['PERMNO'])\n",
    "      decile_permnos['d10_permnos'].append(mdata[mdata['rank']==9]['PERMNO'])\n",
    "\n",
    "    decile_permnos_df = pd.DataFrame(decile_permnos)\n",
    "    decile_permnos_df.sort_values(['monthid'])\n",
    "\n",
    "    # for each time point, we have the permnos of the 1st and 10th decile \n",
    "    # construct equal weighted portfolios \n",
    "    decile_rets = {'monthid': [], 'd1_ret': [], 'd10_ret': []}\n",
    "    mth_groups = stock_data.groupby('monthid')\n",
    "    for _, mdata in mth_groups:\n",
    "      monthid = mdata['monthid'].iloc[0]\n",
    "      # skipping months without data\n",
    "      if not (decile_permnos_df['monthid'].isin([monthid]).any()):\n",
    "        continue\n",
    "      # locate the current monthid's permnos, then filter to those permno and id, and take the mean of the return column \n",
    "      d1_permnos = decile_permnos_df.loc[decile_permnos_df['monthid'] == monthid, 'd1_permnos'].values[0]\n",
    "      d10_permnos = decile_permnos_df.loc[decile_permnos_df['monthid'] == monthid, 'd10_permnos'].values[0]\n",
    "      # filter returns for decile 1 and decile 10 permnos\n",
    "      d1_rets = mdata[mdata['PERMNO'].isin(d1_permnos)]['RET']\n",
    "      d10_rets = mdata[mdata['PERMNO'].isin(d10_permnos)]['RET']\n",
    "      # equal weight d1 and d10 portfolios\n",
    "      decile_rets['monthid'].append(monthid)\n",
    "      decile_rets['d1_ret'].append(-1 * d1_rets.mean()) # short d1 portfolio\n",
    "      decile_rets['d10_ret'].append(d10_rets.mean()) \n",
    "\n",
    "    # return a dataframe of decile returns\n",
    "    decile_rets_df = pd.DataFrame(decile_rets)\n",
    "    decile_rets_df.sort_values([\"monthid\"], inplace=True)\n",
    "    decile_rets_df['d10-d1_ret'] = decile_rets_df['d10_ret'] - decile_rets_df['d1_ret']\n",
    "\n",
    "    capm_ret, ff_ret = Assets.capm_ff_predicted_returns(self.fact.copy())\n",
    "    decile_rets_df['capm_ret'] = capm_ret\n",
    "    decile_rets_df['ff_ret'] = ff_ret\n",
    "    return decile_rets_df\n",
    "  \n",
    "  @staticmethod\n",
    "  def capm_ff_predicted_returns(data):\n",
    "    \"\"\" generate CAPM predicted and FF predicted returns\"\"\"\n",
    "    # factors dataframe contains returns and factors for all permnos and monthids\n",
    "    # estimate beta coefficients\n",
    "    data[\"XRET\"] = data[\"RET\"] - data[\"RF\"]\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # 2 stage regression to get predicted returns \n",
    "    permno_group = data.groupby(\"PERMNO\")\n",
    "    asset_betas = {'PERMNO': [], 'C_MKTRF_b':[], 'F_MKTRF_b': [], 'SMB_b':[], 'HML_b':[], 'UMD_b':[]}\n",
    "    for permno, pdata in permno_group:\n",
    "      # FF factor model to get coefficients\n",
    "      ff_explanatory = pdata[['MKTRF', 'SMB', 'HML', 'UMD']] \n",
    "      ff_explanatory = sm.add_constant(ff_explanatory)\n",
    "      ff_model = sm.OLS(pdata[\"XRET\"], ff_explanatory).fit()\n",
    "      ff_betas = ff_model.params\n",
    "      # CAPM model\n",
    "      capm_explanatory = pdata[['MKTRF']]\n",
    "      capm_explanatory = sm.add_constant(capm_explanatory)\n",
    "      capm_model = sm.OLS(pdata[\"XRET\"], capm_explanatory).fit()\n",
    "      capm_betas = capm_model.params\n",
    "      asset_betas['PERMNO'].append(permno)\n",
    "      asset_betas['C_MKTRF_b'].append(capm_betas['MKTRF'])\n",
    "      asset_betas['F_MKTRF_b'].append(ff_betas['MKTRF'])\n",
    "      asset_betas['SMB_b'].append(ff_betas['SMB'])\n",
    "      asset_betas['HML_b'].append(ff_betas['HML'])\n",
    "      asset_betas['UMD_b'].append(ff_betas['UMD'])\n",
    "\n",
    "    asset_betas_df = pd.DataFrame(asset_betas)\n",
    "    data = pd.merge(data, asset_betas_df, on=[\"PERMNO\"])\n",
    "    month_groups = data.groupby(\"monthid\")\n",
    "\n",
    "    print(asset_betas_df)\n",
    "\n",
    "    # 2nd stage regression is for all assets at each time point\n",
    "    risk_lambdas = {'monthid':[], 'C_MKTRF_l':[], 'F_MKTRF_l': [], 'SMB_l':[], 'HML_l':[], 'UMD_l':[]}\n",
    "    for monthid, mdata in month_groups:\n",
    "      ff_explanatory = mdata[['F_MKTRF_b', 'SMB_b', 'HML_b', 'UMD_b']]\n",
    "      ff_explanatory = sm.add_constant(ff_explanatory)\n",
    "      ff_model = sm.OLS(mdata[\"XRET\"], ff_explanatory).fit()\n",
    "\n",
    "      capm_explanatory = mdata[['C_MKTRF_b']]\n",
    "      capm_explanatory = sm.add_constant(capm_explanatory)\n",
    "      capm_model = sm.OLS(mdata[\"XRET\"], capm_explanatory).fit()\n",
    "\n",
    "      risk_lambdas['monthid'].append(monthid)\n",
    "      risk_lambdas['C_MKTRF_l'].append(capm_model.params['C_MKTRF_b'])\n",
    "      risk_lambdas['F_MKTRF_l'].append(ff_model.params['F_MKTRF_b'])\n",
    "      risk_lambdas['SMB_l'].append(ff_model.params['SMB_b'])\n",
    "      risk_lambdas['HML_l'].append(ff_model.params['HML_b'])\n",
    "      risk_lambdas['UMD_l'].append(ff_model.params['UMD_b'])\n",
    "\n",
    "    # with the risk lambdas, we can predict return\n",
    "    risk_lambdas_df = pd.DataFrame(risk_lambdas)\n",
    "\n",
    "    print(risk_lambdas_df)\n",
    "\n",
    "    predict = pd.merge(data, risk_lambdas_df, on=['monthid'])\n",
    "    predict['capm_ret'] = predict['RF'] + (predict['C_MKTRF_b'] * predict['C_MKTRF_l'])\n",
    "    predict['ff_ret'] = predict['RF'] + (predict['SMB_b']*predict['SMB_l']) + (predict['HML_b']*predict['HML_l']) + (predict['UMD_b']*predict['UMD_l'])\n",
    "\n",
    "    return predict['capm_ret'], predict['ff_ret']\n",
    "    \n",
    " \n",
    "  def performance_analytics(self, returns, ret_col='RET', benchmark='capm', capm_col='capm_ret', ff_col='ff_ret'):\n",
    "    \"\"\" \n",
    "    takes in a dataframe of returns indexed by monthid:\n",
    "    must include columns:\n",
    "        * RET (for returns to calculate analytics for)\n",
    "        * capm_ret (retruns generated via CAPM model)\n",
    "        * ff_ret (returns generated from FF 4 model)\n",
    "\n",
    "    compute metrics on \"resulting out-of-sample returns over all months in the \n",
    "    out of sample period\"\n",
    "    \"\"\"\n",
    "\n",
    "    raw_ret = returns[ret_col].mean()\n",
    "    capm_ret = returns[capm_col].mean()\n",
    "    ff_ret = returns[ff_col].mean()\n",
    "\n",
    "    if (benchmark=='capm'):\n",
    "      benchmark_col = capm_col\n",
    "      benchmark_ret = capm_ret\n",
    "    else:\n",
    "      benchmark_col = ff_col\n",
    "      benchmark_ret = ff_ret\n",
    "      \n",
    "    # CAPM alpha - difference between capm predicted returns and actual returns\n",
    "    capm_alpha = raw_ret - capm_ret\n",
    "    # 4-Factor alpha - difference between 4 factor predicted returns and actual returns\n",
    "    ff_alpha = raw_ret - ff_ret\n",
    "    # sharpe ratio\n",
    "    sr = (raw_ret - capm_ret) / returns[ret_col].std()\n",
    "    # Information ratio \n",
    "    ir = (raw_ret - benchmark_ret) / (returns[ret_col] - returns[benchmark_col]).std()\n",
    "\n",
    "    analytics = {'raw_return': [raw_ret] , 'sharpe_r':[sr], 'capm_alpha': [capm_alpha], 'ff_alpha': [ff_alpha], 'information_r': [ir]}\n",
    "    return pd.DataFrame(analytics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/0pg3_6s57f39kds6_g4kpl680000gn/T/ipykernel_21786/1580489571.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n"
     ]
    }
   ],
   "source": [
    "assets = Assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>EXCHCD</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>OIADPQ</th>\n",
       "      <th>PSTKQ</th>\n",
       "      <th>SALEQ</th>\n",
       "      <th>qtrid</th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>05978R10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>4246.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.250</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10016</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>81002230</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.250</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>13729.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.733</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.084</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>44950710</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.125</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.521</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>00103110</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.500</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>7219.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.031</td>\n",
       "      <td>271</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>46603210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.250</td>\n",
       "      <td>-0.129771</td>\n",
       "      <td>8872.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.964</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>92284</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>00794210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836</td>\n",
       "      <td>1.01</td>\n",
       "      <td>20.347</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>92567</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>19827410</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.375</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>24677.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.400</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>92639</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>90290110</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.875</td>\n",
       "      <td>-0.130319</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.085</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.231</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>92655</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>91324P10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.625</td>\n",
       "      <td>-0.114035</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.164</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>93201</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>98360410</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.500</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>11839.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.845</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.319</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows Ã 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO                        DATE     CUSIP  SHRCD  EXCHCD     PRC  \\\n",
       "0         10002  1998-01-30 00:00:00.000000  05978R10   11.0     3.0  25.000   \n",
       "1         10016  1998-01-30 00:00:00.000000  81002230   11.0     3.0  13.250   \n",
       "2         10019  1998-01-30 00:00:00.000000  44950710   11.0     3.0  16.125   \n",
       "3         10025  1998-01-30 00:00:00.000000  00103110   11.0     3.0  33.500   \n",
       "4         10026  1998-01-30 00:00:00.000000  46603210   11.0     3.0  14.250   \n",
       "...         ...                         ...       ...    ...     ...     ...   \n",
       "1242503   92284  1986-06-30 00:00:00.000000  00794210   11.0     3.0  16.000   \n",
       "1242504   92567  1986-06-30 00:00:00.000000  19827410   11.0     3.0  14.375   \n",
       "1242505   92639  1986-06-30 00:00:00.000000  90290110   10.0     3.0  40.875   \n",
       "1242506   92655  1986-06-30 00:00:00.000000  91324P10   11.0     3.0  12.625   \n",
       "1242507   93201  1986-06-30 00:00:00.000000  98360410   11.0     3.0  15.500   \n",
       "\n",
       "              RET   SHROUT  year  month  ...  OIADPQ  PSTKQ    SALEQ qtrid  \\\n",
       "0        0.020408   4246.0  1998      1  ...   2.154   0.00    7.250   273   \n",
       "1        0.009524  13729.0  1998      1  ...   5.733   0.00   38.084   273   \n",
       "2        0.040323   8205.0  1998      1  ...   3.179   0.00   25.521   273   \n",
       "3        0.085020   7219.0  1998      1  ...  10.677   0.00  198.031   271   \n",
       "4       -0.129771   8872.0  1998      1  ...   5.293   0.00   62.964   273   \n",
       "...           ...      ...   ...    ...  ...     ...    ...      ...   ...   \n",
       "1242503  0.049180   9064.0  1986      6  ...   1.836   1.01   20.347   132   \n",
       "1242504  0.017699  24677.0  1986      6  ...   2.257   0.00   84.400   132   \n",
       "1242505 -0.130319   5486.0  1986      6  ...   5.085   0.00   14.231   132   \n",
       "1242506 -0.114035  15167.0  1986      6  ...   2.016   0.00   32.164   132   \n",
       "1242507 -0.088235  11839.0  1986      6  ...   5.845   0.00   44.319   132   \n",
       "\n",
       "            DATEFF     SMB     HML   MKTRF      RF     UMD  \n",
       "0       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "1       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "2       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "3       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "4       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "...            ...     ...     ...     ...     ...     ...  \n",
       "1242503 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242504 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242505 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242506 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242507 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "\n",
       "[1242508 rows x 37 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "      <th>monthid</th>\n",
       "      <th>epq1</th>\n",
       "      <th>RET</th>\n",
       "      <th>PERMNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>10006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>10102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>10137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.136564</td>\n",
       "      <td>10145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>10161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.143199</td>\n",
       "      <td>93397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>93423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>93426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>93427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>93436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows Ã 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATEFF     SMB     HML   MKTRF      RF     UMD  monthid      epq1  \\\n",
       "0       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "1       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "2       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "3       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "4       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "...            ...     ...     ...     ...     ...     ...      ...       ...   \n",
       "1242503 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242504 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242505 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242506 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242507 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "\n",
       "              RET  PERMNO  \n",
       "0        0.231061   10006  \n",
       "1        0.337349   10102  \n",
       "2        0.333333   10137  \n",
       "3        0.136564   10145  \n",
       "4        0.215447   10161  \n",
       "...           ...     ...  \n",
       "1242503  0.143199   93397  \n",
       "1242504  0.109665   93423  \n",
       "1242505  0.076239   93426  \n",
       "1242506  0.135851   93427  \n",
       "1242507  0.243252   93436  \n",
       "\n",
       "[1242508 rows x 10 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_error</th>\n",
       "      <th>tstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epq1</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>6.958548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          mean  std_error     tstat\n",
       "epq1  0.001333   0.000192  6.958548"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.factor_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assets.fact.to_csv('assets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>monthid</th>\n",
       "      <th>alpha</th>\n",
       "      <th>epq1_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>277</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>-0.182048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008734</td>\n",
       "      <td>0.314555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10010</td>\n",
       "      <td>205</td>\n",
       "      <td>-0.012875</td>\n",
       "      <td>0.302951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10016</td>\n",
       "      <td>139</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.060052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10017</td>\n",
       "      <td>140</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.290105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>93060</td>\n",
       "      <td>229</td>\n",
       "      <td>0.018277</td>\n",
       "      <td>0.235921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>93105</td>\n",
       "      <td>265</td>\n",
       "      <td>0.033813</td>\n",
       "      <td>-0.232814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7887</th>\n",
       "      <td>93156</td>\n",
       "      <td>181</td>\n",
       "      <td>0.061310</td>\n",
       "      <td>-0.515262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7888</th>\n",
       "      <td>93201</td>\n",
       "      <td>133</td>\n",
       "      <td>-0.059437</td>\n",
       "      <td>2.295639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7889</th>\n",
       "      <td>93220</td>\n",
       "      <td>169</td>\n",
       "      <td>0.174426</td>\n",
       "      <td>-6.568572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7890 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      PERMNO  monthid     alpha    epq1_b\n",
       "0      10002      277  0.019243 -0.182048\n",
       "1      10006        1  0.008734  0.314555\n",
       "2      10010      205 -0.012875  0.302951\n",
       "3      10016      139  0.002761  0.060052\n",
       "4      10017      140  0.013788  0.290105\n",
       "...      ...      ...       ...       ...\n",
       "7885   93060      229  0.018277  0.235921\n",
       "7886   93105      265  0.033813 -0.232814\n",
       "7887   93156      181  0.061310 -0.515262\n",
       "7888   93201      133 -0.059437  2.295639\n",
       "7889   93220      169  0.174426 -6.568572\n",
       "\n",
       "[7890 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.gen_factor_betas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PERMNO  C_MKTRF_b  F_MKTRF_b      SMB_b     HML_b      UMD_b\n",
      "0       10002   0.465144   0.407501   0.464531  2.079725   0.183559\n",
      "1       10006   1.074352   1.007374   0.351226  0.181622   0.048042\n",
      "2       10010   3.199802   2.073939   1.276142  0.171664   2.767446\n",
      "3       10012   2.871593  -6.412176  -8.639767 -7.244200   8.191616\n",
      "4       10016   0.750906   1.092842   0.827613  1.159553  -0.242292\n",
      "...       ...        ...        ...        ...       ...        ...\n",
      "12164   93428   1.493261   1.244205   1.453315 -0.702493   0.064504\n",
      "12165   93429   0.633694   0.683048   0.055801  0.714426   0.484314\n",
      "12166   93433   2.329647   4.297205 -14.322695 -4.768507  16.075954\n",
      "12167   93435   4.735184   1.770314  -1.161409  1.950178  -1.200404\n",
      "12168   93436   1.761013   1.729920   0.298677 -0.965724  -0.273022\n",
      "\n",
      "[12169 rows x 6 columns]\n",
      "     monthid  C_MKTRF_l  F_MKTRF_l     SMB_l     HML_l     UMD_l\n",
      "0          1   0.106307   0.045803  0.130271  0.140088 -0.133316\n",
      "1          2   0.038544   0.033994 -0.010277 -0.087238 -0.012373\n",
      "2          3   0.083244   0.049209  0.049074 -0.024957 -0.035035\n",
      "3          4   0.074441   0.069531 -0.000276 -0.049306  0.004226\n",
      "4          5  -0.017510  -0.006657 -0.006883 -0.025583  0.006180\n",
      "..       ...        ...        ...       ...       ...       ...\n",
      "547      548   0.033999   0.046066 -0.010161 -0.010588 -0.003087\n",
      "548      549  -0.018577  -0.023646 -0.009851 -0.019441  0.016447\n",
      "549      550  -0.011751  -0.032146  0.025926  0.050405 -0.022885\n",
      "550      551   0.121609   0.113507  0.049584  0.033598 -0.142566\n",
      "551      552   0.024972   0.016897  0.042924  0.001648 -0.024197\n",
      "\n",
      "[552 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "rets = assets.score_linear()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthid</th>\n",
       "      <th>d1_ret</th>\n",
       "      <th>d10_ret</th>\n",
       "      <th>d10-d1_ret</th>\n",
       "      <th>capm_ret</th>\n",
       "      <th>ff_ret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.087456</td>\n",
       "      <td>0.216093</td>\n",
       "      <td>0.303549</td>\n",
       "      <td>0.120011</td>\n",
       "      <td>0.070593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.149248</td>\n",
       "      <td>0.202267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25</td>\n",
       "      <td>-0.063702</td>\n",
       "      <td>0.239341</td>\n",
       "      <td>0.303043</td>\n",
       "      <td>0.065847</td>\n",
       "      <td>0.096005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124148</td>\n",
       "      <td>0.058016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.155704</td>\n",
       "      <td>0.110212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.174247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098907</td>\n",
       "      <td>-0.053860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>349</td>\n",
       "      <td>0.026831</td>\n",
       "      <td>0.142416</td>\n",
       "      <td>0.115585</td>\n",
       "      <td>0.131201</td>\n",
       "      <td>0.125796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>352</td>\n",
       "      <td>0.347930</td>\n",
       "      <td>0.101477</td>\n",
       "      <td>-0.246453</td>\n",
       "      <td>0.119174</td>\n",
       "      <td>0.093061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>355</td>\n",
       "      <td>0.107494</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.097634</td>\n",
       "      <td>0.082137</td>\n",
       "      <td>0.129383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>361</td>\n",
       "      <td>0.119498</td>\n",
       "      <td>0.074977</td>\n",
       "      <td>-0.044521</td>\n",
       "      <td>0.134242</td>\n",
       "      <td>0.111931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    monthid    d1_ret   d10_ret  d10-d1_ret  capm_ret    ff_ret\n",
       "0         1 -0.087456  0.216093    0.303549  0.120011  0.070593\n",
       "1        13       NaN  0.362010         NaN  0.149248  0.202267\n",
       "2        25 -0.063702  0.239341    0.303043  0.065847  0.096005\n",
       "3        37       NaN       NaN         NaN  0.124148  0.058016\n",
       "4        49       NaN  0.247100         NaN  0.155704  0.110212\n",
       "..      ...       ...       ...         ...       ...       ...\n",
       "57      340       NaN  0.174247         NaN  0.098907 -0.053860\n",
       "58      349  0.026831  0.142416    0.115585  0.131201  0.125796\n",
       "59      352  0.347930  0.101477   -0.246453  0.119174  0.093061\n",
       "60      355  0.107494  0.205128    0.097634  0.082137  0.129383\n",
       "61      361  0.119498  0.074977   -0.044521  0.134242  0.111931\n",
       "\n",
       "[62 rows x 6 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10292327625486575\n",
      "0.23968165216504778\n",
      "0.199998308836006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_return</th>\n",
       "      <th>sharpe_r</th>\n",
       "      <th>capm_alpha</th>\n",
       "      <th>ff_alpha</th>\n",
       "      <th>information_r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102923</td>\n",
       "      <td>-0.806594</td>\n",
       "      <td>-0.136758</td>\n",
       "      <td>-0.097075</td>\n",
       "      <td>-0.73459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_return  sharpe_r  capm_alpha  ff_alpha  information_r\n",
       "0    0.102923 -0.806594   -0.136758 -0.097075       -0.73459"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.performance_analytics(rets, ret_col='d10-d1_ret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Assets' object has no attribute 'regress_factors'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[96], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m assets\u001b[38;5;241m.\u001b[39mregress_factors()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Assets' object has no attribute 'regress_factors'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
