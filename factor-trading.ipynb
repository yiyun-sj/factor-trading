{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandasql import sqldf\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from finance_byu.fama_macbeth import fama_macbeth, fm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRSP = pd.read_sas('crsp.sas7bdat', encoding='latin-1') #fp3v1\n",
    "COMP = pd.read_sas('comp.sas7bdat', encoding='latin-1') #fp3v2\n",
    "FF4 = pd.read_sas('ff4data.sas7bdat', encoding='latin-1')\n",
    "COMP_ANNUAL = pd.read_sas('comp_annual.sas7bdat', encoding='latin-1') # fp3v3\n",
    "INDUSTRY =  pd.read_csv('industries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zero(df, var):\n",
    "    temp = df[var].isna().sum()\n",
    "    df[var].fillna(0, inplace=True)\n",
    "    print(\"NAN values for \" + str(var) + \": \" + str(temp))\n",
    "    temp = df[var].isna().sum()\n",
    "    print(\"NAN values for \" + str(var) + \" filled: \" + str(temp) + \" remaining\")\n",
    "\n",
    "def calculate_credit_metrics(compustat_data):\n",
    "    credit_metrics_df = pd.DataFrame()\n",
    "\n",
    "    # Rename \n",
    "    credit_metrics_df[\"Total_Assets\"] = compustat_data[\"AT\"]\n",
    "    credit_metrics_df[\"Current_Liabilities\"] = compustat_data[\"LCO\"]\n",
    "    credit_metrics_df[\"Long_Term_Debt\"] = compustat_data[\"DLTT\"]\n",
    "    credit_metrics_df[\"Total_Liabilities\"] = compustat_data[\"LT\"]\n",
    "    credit_metrics_df[\"Preferred_Stock\"] = compustat_data[\"PSTK\"]\n",
    "    credit_metrics_df[\"Interest_Expense\"] = compustat_data[\"XINT\"]\n",
    "    credit_metrics_df[\"Cash_Short_Term_Investments\"] = compustat_data[\"CHE\"]\n",
    "    credit_metrics_df[\"Net_Income\"] = compustat_data[\"NI\"]\n",
    "    credit_metrics_df[\"Inventory\"] = compustat_data[\"INVT\"]\n",
    "    credit_metrics_df[\"Total_Equity\"] = compustat_data[\"CEQ\"]\n",
    "\n",
    "    # Calculate financial ratios\n",
    "    credit_metrics_df[\"Debt_Equity_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Debt_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Current_Ratio\"] = credit_metrics_df[\"Current_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Quick_Ratio\"] = (credit_metrics_df[\"Current_Liabilities\"] - credit_metrics_df[\"Inventory\"]) / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Interest_Coverage_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Interest_Expense\"]\n",
    "    credit_metrics_df[\"Return_On_Assets\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Return_On_Equity\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Asset_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Inventory_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Inventory\"]\n",
    "\n",
    "    return credit_metrics_df\n",
    "\n",
    "def calculate_credit_score(credit_metrics_df):\n",
    "    # Define weights for each financial metric\n",
    "    weights = {\n",
    "        \"Debt_Equity_Ratio\": 0.2,\n",
    "        \"Debt_Ratio\": 0.1,\n",
    "        \"Current_Ratio\": 0.1,\n",
    "        \"Quick_Ratio\": 0.1,\n",
    "        \"Interest_Coverage_Ratio\": 0.1,\n",
    "        \"Return_On_Assets\": 0.1,\n",
    "        \"Return_On_Equity\": 0.1,\n",
    "        \"Asset_Turnover_Ratio\": 0.1,\n",
    "        \"Inventory_Turnover_Ratio\": 0.1\n",
    "    }\n",
    "\n",
    "    # Calculate the weighted sum of normalized metrics\n",
    "    credit_score = (credit_metrics_df * pd.Series(weights)).sum(axis=1)\n",
    "\n",
    "    return credit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factors:\n",
    "  @staticmethod\n",
    "  def _create_hedge_portfolio(data: pd.DataFrame, factor_col: str, q=10, direction=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a hedge portfolio, using D10 - D1 returns by default.\n",
    "\n",
    "    Args:\n",
    "      data (pd.DataFrame): Data, must contain columns ['monthid', 'RET', factor_col]\n",
    "      factor_col (str): Name of factor column, i.e. ep1\n",
    "      q (int, optional): Defaults to deciles (10).\n",
    "      direction (int, optional): Either 1 or -1. If 1, we do High - Low. Otherwise, Low - High.\n",
    "\n",
    "    Returns: Return of hedge portfolio at each monthid (i.e. the factor)\n",
    "    \"\"\"\n",
    "    factor = []\n",
    "    index = []  # monthid - 1\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp[factor_col].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    for monthid, mdata in mth_grp:\n",
    "      # TODO: can add value weighting of returns here if anyone needs it\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == q-1]['RET'].mean()\n",
    "      factor.append(direction * (d10 - d1))\n",
    "      index.append(monthid - 1)\n",
    "    return pd.DataFrame(factor, index=index)\n",
    "  \n",
    "  @staticmethod\n",
    "  def dNoa(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    # annual_data = COMP_ANNUAL\n",
    "    fill_zero(annual_data, 'DLC')\n",
    "    fill_zero(annual_data, 'DLTT')\n",
    "    fill_zero(annual_data, 'MIB')\n",
    "    fill_zero(annual_data, 'PSTK')\n",
    "\n",
    "    operating_assets = annual_data[\"AT\"] - annual_data[\"CHE\"]\n",
    "    operating_liabilities = annual_data[\"AT\"] - annual_data[\"DLC\"] - annual_data[\"DLTT\"] - annual_data[\"MIB\"] - annual_data[\"PSTK\"] - annual_data[\"CEQ\"]\n",
    "\n",
    "    Noa = operating_assets - operating_liabilities\n",
    "\n",
    "    lagged_total_assets = annual_data[\"AT\"].shift(1)  # 1-year-lagged total assets\n",
    "    dNoa = (Noa - Noa.shift(1)) / lagged_total_assets\n",
    "\n",
    "    annual_data[\"dNoa\"] = dNoa\n",
    "    annual_data[\"dNoa\"].fillna(0, inplace=True)\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNoa \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNoa'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def Nsi(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "\n",
    "    annual_data[\"CSHO_t_minus_1_adjusted\"] = annual_data[\"CSHO\"] * annual_data[\"AJEX\"]\n",
    "\n",
    "    test_shifted = annual_data.shift(periods=1)\n",
    "    annual_data[\"CSHO_t_minus_2_adjusted\"] = test_shifted[\"CSHO\"] * test_shifted[\"AJEX\"]\n",
    "\n",
    "    annual_data[\"Nsi_u\"] = np.log(annual_data[\"CSHO_t_minus_1_adjusted\"] / annual_data[\"CSHO_t_minus_2_adjusted\"])\n",
    "    annual_data[\"Nsi_u\"].fillna(0, inplace=True)\n",
    "\n",
    "    annual_data[\"Nsi\"] = np.where(annual_data[\"Nsi_u\"] < 0, np.where(annual_data[\"Nsi_u\"] < annual_data[\"Nsi_u\"].quantile(0.5), 1, 2),\n",
    "                             np.where(annual_data[\"Nsi_u\"] == 0, 3,\n",
    "                                      np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.1), 4,\n",
    "                                               np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.2), 5,\n",
    "                                                        np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.3), 6,\n",
    "                                                                 np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.4), 7,\n",
    "                                                                          np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.5), 8,\n",
    "                                                                                   np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.6), 9, 10))))))))\n",
    "    annual_data[\"Nsi\"]\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.Nsi \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Nsi'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dNca(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"IVAO\")\n",
    "\n",
    "    annual_data[\"Nca\"] = annual_data[\"AT\"] - annual_data[\"ACT\"] - annual_data[\"IVAO\"]\n",
    "    annual_data[\"dNca_o\"] = annual_data[\"Nca\"].diff()\n",
    "    annual_data[\"dNca_o\"].fillna(0, inplace=True)\n",
    "\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dNca\"] = annual_data[\"dNca_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dFnl(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"DLTT\")\n",
    "    fill_zero(annual_data, \"DLC\")\n",
    "    fill_zero(annual_data, \"PSTK\")\n",
    "\n",
    "    annual_data[\"Fnl\"] = annual_data[\"DLTT\"] + annual_data[\"DLC\"] + annual_data[\"PSTK\"]\n",
    "    annual_data[\"dFnl_o\"] = annual_data[\"Fnl\"].diff()\n",
    "    annual_data[\"dFnl_o\"].fillna(0, inplace=True)\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dFnl\"] = annual_data[\"dFnl_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dFnl \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dFnl'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def creditrisk(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    credit_metrics = calculate_credit_metrics(annual_data)\n",
    "    credit_score = calculate_credit_score(credit_metrics)\n",
    "    annual_data[\"cdrk\"] = credit_score\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.cdrk \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['cdrk'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def epq1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data = data[data['IBQ'] >= 0]\n",
    "    data['Epq1'] = data['IBQ'] * 1000000 / data['MKTCAP']\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Epq1'].transform(lambda x: pd.qcut(x, 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d1 - d10)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ioca(data):\n",
    "    CPI = pd.read_csv('cpi.csv')\n",
    "    g = .10\n",
    "    d = .15\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data = pd.merge(annual_data, CPI, on='year')\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    grouped = annual_data.groupby('LPERMNO')\n",
    "    oc = []\n",
    "    for _, grp in grouped:\n",
    "      prev = None\n",
    "      for _, row in grp.iterrows():\n",
    "        if prev == None:\n",
    "          prev = row['XSGA'] / (g+d)\n",
    "        else:\n",
    "          prev = (1 - d) * prev + row['XSGA'] / row['CPI']\n",
    "        oc.append(prev)\n",
    "    annual_data['oc'] = oc\n",
    "    annual_data = annual_data[(annual_data['oc'] > 0) & (annual_data['AT'] > 0)]\n",
    "    annual_data['oca'] = annual_data['oc'] / annual_data['AT']\n",
    "    def yearly_winsorize(srs):\n",
    "      p1, p99 = np.nanpercentile(srs, [1, 99])\n",
    "      return np.clip(srs, p1, p99)\n",
    "    annual_data['ioca'] = annual_data.groupby('year')['oca'].transform(yearly_winsorize)\n",
    "    annual_data['ioca'] = annual_data.groupby('industry')['ioca'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "    data = sqldf(\"SELECT a.*, b.ioca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['ioca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ra26(data):\n",
    "    factor = []\n",
    "    data = data.sort_values(['PERMNO','monthid'])\n",
    "    datagrp = data.groupby('PERMNO')\n",
    "    for _, grp in datagrp:\n",
    "      for mid in grp['monthid']:\n",
    "        tm = grp[grp['monthid'].isin([mid - 24, mid - 36, mid - 48, mid - 60])]\n",
    "        if (len(tm) < 4):\n",
    "          factor.append(np.NaN)\n",
    "        else:\n",
    "          factor.append(tm['RET'].mean())\n",
    "    data['ra26'] = factor\n",
    "    return Factors._create_hedge_portfolio(data, 'ra26')\n",
    "\n",
    "  @staticmethod\n",
    "  def Abr1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "\n",
    "    # RET_DAILY = pd.read_sas('ret_daily.sas7bdat', encoding='latin-1')  sas is SLOW\n",
    "    ret_daily = pd.read_parquet(\"ret_daily.parquet\")\n",
    "    vwret = pd.read_sas('us_vwret.sas7bdat', encoding='latin-1').set_index(\"date\")\n",
    "\n",
    "    ret_daily[\"monthid\"] = (ret_daily.DATE.dt.year-1975)*12 + ret_daily.DATE.dt.month\n",
    "\n",
    "    stock_returns = ret_daily.set_index([\"PERMNO\", \"DATE\"]).sort_index()\n",
    "    del ret_daily  # save memory\n",
    "    # faster to pivot first and then do the operations, rather than doing a groupby\n",
    "    stock_returns = stock_returns.pivot_table(values=\"RET\", columns=\"PERMNO\", index=\"DATE\")\n",
    "    stock_returns = stock_returns.sub(vwret.VWRETD, axis=0)  # return over market\n",
    "\n",
    "    # get all 4-period returns from T-3 to T+1\n",
    "    stock_returns = stock_returns.rolling(4).sum().shift(-1)\n",
    "    stock_returns = pd.DataFrame(stock_returns.stack())\n",
    "    stock_returns = stock_returns.rename(columns={0:\"Abr\"})\n",
    "\n",
    "    # Merge on RDQ date so we only have the returns around earnings date\n",
    "    rdqs = data[[\"PERMNO\", \"RDQ\"]].dropna()\n",
    "    rdqs.RDQ = pd.to_datetime(rdqs.RDQ)\n",
    "    rdqs = rdqs.drop_duplicates()\n",
    "    rdqs = rdqs.merge(stock_returns, left_on=[\"RDQ\", \"PERMNO\"], right_index=True, how=\"left\")\n",
    "    del stock_returns  # save memory\n",
    "    # This is the date we use to calculate the monthid to avoid lookahead bias,\n",
    "    # since Abr is calculated using RDQ-3 to RDQ+1 returns.\n",
    "    rdqs[\"RDQ+1\"] = rdqs.RDQ + pd.offsets.BDay(1)\n",
    "    rdqs[\"monthid\"] = (rdqs[\"RDQ+1\"].dt.year-1975)*12 + rdqs[\"RDQ+1\"].dt.month\n",
    "\n",
    "    rdqs = rdqs.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # duplicates can occur where RDQ is in the same month. We drop the first month-PERMNO duplicate\n",
    "    rdqs = rdqs[~rdqs.index.duplicated(keep=\"last\")]\n",
    "\n",
    "    final = pd.DataFrame(index=data.set_index([\"PERMNO\", \"monthid\"]).index).sort_index()\n",
    "    final[\"Abr1\"] = rdqs.Abr\n",
    "    # forward fill only 6 months to avoid stale data\n",
    "    # TODO: could possibly be problems if data skips some monthids, but we still have no lookahead bias, just possible stale data\n",
    "    final = final.groupby(level=0).ffill(limit=6)\n",
    "\n",
    "    data = data.merge(final, how=\"left\", left_on=[\"PERMNO\", \"monthid\"], right_index=True).sort_values(by=['PERMNO', 'monthid'])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"Abr1\", q=10, direction=1)\n",
    "    # return data\n",
    "\n",
    "  @staticmethod\n",
    "  def e11(data):\n",
    "    \"\"\"\n",
    "    Calculate ε11 factor (Residual momentum, prior 11-month returns) with 1 month holding period.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Get a series of rf indexed by date\n",
    "    rf = data.set_index(\"monthid\")[[\"RF\"]].reset_index().drop_duplicates(subset=\"monthid\")\n",
    "    rf = rf.set_index(\"monthid\").sort_index().RF\n",
    "\n",
    "    # Get xret with each permno in a column\n",
    "    xret = data.loc[:,~data.columns.duplicated()].pivot_table(index=\"monthid\", columns=\"PERMNO\", values=\"RET\").sort_index()\n",
    "    xret = xret.sub(rf, axis=0)\n",
    "\n",
    "    # Get ff data with constant\n",
    "    ff_3 = data[[\"monthid\", \"SMB\", \"HML\", \"MKTRF\"]].drop_duplicates(subset=\"monthid\").set_index(\"monthid\").sort_index()\n",
    "    ff_3 = sm.add_constant(ff_3)\n",
    "\n",
    "    from numpy.linalg import pinv\n",
    "\n",
    "    def last_ff_residual(series: pd.Series, ff: pd.DataFrame) -> float:\n",
    "      \"\"\"Computes FF residuals for a series of excess returns.\n",
    "\n",
    "      Args:\n",
    "        series (pd.DataFrame): rolling excess returns. Must have no null values.\n",
    "        ff (pd.DataFrame): factors, must have overlapping index with `series`. All columns are used as factors. Must have constant column added.\n",
    "\n",
    "      Returns: residual on last date T\n",
    "      \"\"\"\n",
    "      # y = series\n",
    "      x = ff.loc[series.index]\n",
    "      \n",
    "      # ffmodel = sm.OLS(y, x).fit()\n",
    "      # residual_values = ffmodel.resid\n",
    "\n",
    "      # sm.OLS is too slow, do it with linear algebra instead\n",
    "      params = pinv(x).dot(series)\n",
    "\n",
    "      # calculate last residual\n",
    "      t_residual = series.iloc[-1] - x.iloc[-1].dot(params)\n",
    "      \n",
    "      return t_residual\n",
    "\n",
    "    residuals = xret.rolling(window=36, min_periods=36).apply(\n",
    "      lambda series: last_ff_residual(series, ff_3)\n",
    "    )\n",
    "    scaled_residuals = residuals / residuals.rolling(36, min_periods=12).std()\n",
    "\n",
    "    # The time T residual momentum is the sum of residual returns for T-12, T-11, ... T-1\n",
    "    # We do this with a rolling 11 period sum, and then shift down by 1\n",
    "    e11 = scaled_residuals.rolling(11).sum().shift()\n",
    "\n",
    "    # Reshape so the columns are [monthid, PERMNO, e11] and merge into data\n",
    "    e11 = pd.DataFrame(e11.stack()).rename(columns={0: \"e11\"})\n",
    "    data = data.merge(e11, how=\"left\", left_on=[\"monthid\", \"PERMNO\"], right_index=True)\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"e11\", q=10, direction=1)\n",
    "\n",
    "  @staticmethod\n",
    "  def Re1(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    ibes_link = pd.read_csv(\"crsp_ibes_link.csv\")  # ibes ticker to PERMNO map  https://wrds-www.wharton.upenn.edu/pages/get-data/linking-suite-wrds/ibes-crsp-link/\n",
    "    ibes_eps = pd.read_csv(\"ibes_eps_estimate.csv\")  # Mean EPS estimates  https://wrds-www.wharton.upenn.edu/pages/get-data/ibes-thomson-reuters/ibes-academic/summary-history/summary-statistics/\n",
    "\n",
    "    ibes_link = ibes_link.dropna()\n",
    "\n",
    "    # Only want USD currency\n",
    "    ibes_eps = ibes_eps[ibes_eps.CURCODE == \"USD\"]\n",
    "\n",
    "    # Get the estimates with the date and permno\n",
    "    eps_est = sqldf(\n",
    "      \"\"\"\n",
    "      select l.permno, e.STATPERS as DATE, e.MEANEST\n",
    "      from ibes_eps e\n",
    "      left join ibes_link l\n",
    "      on e.ticker = l.TICKER and e.STATPERS >= l.sdate and e.STATPERS <= l.edate \n",
    "      \"\"\"\n",
    "    )\n",
    "\n",
    "    # Add monthid\n",
    "    eps_est = eps_est.drop_duplicates(subset=[\"DATE\", \"PERMNO\"])\n",
    "    eps_est.DATE = pd.to_datetime(eps_est.DATE)\n",
    "    eps_est['monthid'] = (eps_est.DATE.dt.year-1975)*12 + eps_est.DATE.dt.month\n",
    "\n",
    "    # Merge close price\n",
    "    eps_est = eps_est.merge(data.set_index([\"monthid\", \"PERMNO\"]).PRC, on=[\"monthid\", \"PERMNO\"])\n",
    "    eps_est = eps_est.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # Calculate factor value for each stock\n",
    "\n",
    "    # TODO: we should make PRC the split adjusted price as our EPS values are split adjusted\n",
    "    re = eps_est.reset_index().set_index(\"monthid\").sort_index().groupby([\"PERMNO\"]).apply(\n",
    "        # 6 period rolling sum of (f_t - f_t-1) / p_t-1, requiring at least 4 consecutive observations\n",
    "        lambda df: ((df.MEANEST - df.MEANEST.shift()) / df.PRC.shift()).rolling(window=6, min_periods=4).sum()\n",
    "    )\n",
    "    eps_est[\"Re1\"] = re\n",
    "    \n",
    "    data = data.merge(eps_est[[\"Re1\"]], how=\"left\", on=[\"monthid\", \"PERMNO\"])\n",
    "    \n",
    "    return Factors._create_hedge_portfolio(data, \"Re1\", q=10, direction=1)\n",
    "  \n",
    "\n",
    "  # D. Investment ==========================================\n",
    "  @staticmethod \n",
    "  def _compute_shifted(data, factor_col, input_col1, input_col2, shift_amt, op='-'):\n",
    "    \"\"\"\n",
    "    for factor calculations that require a shift of data values to avoid\n",
    "    lookahead bias:\n",
    "    Input:\n",
    "      data: DataFrame\n",
    "      factor_col: name of factor to be computed\n",
    "      input_col: name of column used in the factor computation\n",
    "      shift_amt: number of months to lag by for input_col\n",
    "    Return:\n",
    "      a dataframe with cols ['monthid', 'PERMNO', 'factor'] for merge\n",
    "      into the overall data\n",
    "    \"\"\"\n",
    "    permno_grp = data.groupby('PERMNO')\n",
    "    # construct a mini dataframe of shifted values -> (monthid, permno, dRoa1 computed for the relevant month)\n",
    "    factor_values = {'monthid': [], 'PERMNO': [], factor_col:[]}\n",
    "\n",
    "    for _, pdata in permno_grp:\n",
    "      # sort by monthid\n",
    "      pdata = pdata.sort_values('monthid') \n",
    "      # lag Roa to avoid lookahead bias\n",
    "      if (op == '-'):\n",
    "        pdata[factor_col] = pdata[input_col1] - pdata[input_col2].shift(shift_amt)\n",
    "      else:\n",
    "        pdata[factor_col] = pdata[input_col1] / pdata[input_col2].shift(shift_amt)\n",
    "      # add to dataframe\n",
    "      \n",
    "      factor_values['PERMNO'].extend(pdata['PERMNO'].tolist())\n",
    "      factor_values['monthid'].extend(pdata['monthid'].tolist())\n",
    "      factor_values[factor_col].extend(pdata[factor_col].tolist())\n",
    "\n",
    "    factor_values = pd.DataFrame(factor_values)\n",
    "    factor_values['monthid'] = factor_values['monthid'].astype(np.int64)\n",
    "    factor_values['PERMNO'] = factor_values['PERMNO'].astype(np.int64)\n",
    "\n",
    "    return pd.DataFrame(factor_values)\n",
    "    \n",
    "  @staticmethod\n",
    "  def droe1(data):\n",
    "    \"\"\"dRoe: return on equity minus its value from four quarters ago \"\"\"\n",
    "    #   for each month t, sort all stocks into deciles based on their most recent past dRoe\n",
    "    #   monthly decile returns calculated for the current month t\n",
    "\n",
    "    # ROE = NET (RDQ) / Equity (CEQQ)   \n",
    "    data = data.copy()\n",
    "    data['Roe'] = data['NIQ'] / data['CEQQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoe1', input_col1='Roe', input_col2='Roe', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoe1\", q=10)\n",
    "  \n",
    "  @staticmethod\n",
    "  def droa1(data):\n",
    "    \"\"\" droa1 \"is return on assets minus its value from four quarters ago\" \"\"\"\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data['Roa'] = data['NIQ'] / data['ATQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoa1', input_col1='Roa', input_col2='Roa', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoa1\", q=10)\n",
    "\n",
    "  @staticmethod\n",
    "  def rnaq1(data):\n",
    "    \"\"\" Rnaq1: Quarterly return on net operating assets \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='rnaq1', input_col1='OIADPQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'rnaq1')\n",
    "\n",
    "  @staticmethod\n",
    "  def atoq1(data):\n",
    "    \"\"\" atoq1: quarterly sales divided by 1-quarter-lagged Noa \"\"\"\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='atoq1', input_col1='SALEQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'atoq1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assets:\n",
    "  crsp = CRSP.copy()\n",
    "  comp = COMP.copy()\n",
    "  ff4 = FF4.copy()\n",
    "  fact = pd.DataFrame()\n",
    "  data = pd.DataFrame()\n",
    "  # train_start = '1975-01-01'\n",
    "  # train_end = '2005-12-31'\n",
    "  # test_start = '2006-01-01'\n",
    "  # test_end = '2020-12-31'\n",
    "  factors = {\n",
    "    'epq1': Factors.epq1,\n",
    "    'ioca': Factors.ioca,\n",
    "    'ra26': Factors.ra26,\n",
    "    'e11': Factors.e11,  # comment out for now as this takes ~12min to run\n",
    "    'Re1': Factors.Re1,\n",
    "    'Abr1': Factors.Abr1,\n",
    "\n",
    "    # D. Investment =====================================\n",
    "    'dRoe1': Factors.droe1,\n",
    "    'dRoa1': Factors.droa1,\n",
    "    'rnaq1': Factors.rnaq1,\n",
    "    'atoq1': Factors.atoq1,\n",
    "\n",
    "    'dNoa': Factors.dNoa,\n",
    "    'Nsi': Factors.Nsi,\n",
    "    'dNca': Factors.dNca,\n",
    "    'dFnl' : Factors.dFnl\n",
    "    # 'creditrisk': Factors.creditrisk\n",
    "  }\n",
    "  factor_t = {}\n",
    "  \n",
    "  def __init__(self, start_date=None):\n",
    "\n",
    "    # Make testing faster by optiSonally limiting dates\n",
    "    if start_date is not None:\n",
    "      self.crsp = self.crsp[self.crsp.DATE >= start_date]\n",
    "      self.comp = self.comp[self.comp.DATADATE >= start_date]\n",
    "\n",
    "    self.clean_crsp()\n",
    "    self.clean_comp()\n",
    "    self.clean_ff4()\n",
    "    self.illiquidity_filter()\n",
    "    \n",
    "    self.merge_data()\n",
    "    self.gen_factors()\n",
    "    self.fama_macbeth()\n",
    "    \n",
    "  def clean_crsp(self):\n",
    "    self.crsp['PERMNO'] = self.crsp['PERMNO'].astype(int)\n",
    "    self.crsp['year'] = self.crsp['DATE'].dt.year\n",
    "    self.crsp['month'] = self.crsp['DATE'].dt.month\n",
    "    self.crsp['monthid'] = (self.crsp['year']-1975)*12 + self.crsp['month']\n",
    "    self.crsp['PRC'] = self.crsp['PRC'].apply(lambda x: x if x > 0 else x * -1)\n",
    "    \n",
    "  def clean_comp(self):\n",
    "    self.comp['qtrid'] = (self.comp['DATADATE'].dt.year-1975)*12 + self.comp['DATADATE'].dt.month\n",
    "    self.comp['LPERMNO'] = self.comp['LPERMNO'].astype(int)\n",
    "    self.comp.drop(columns=['CONSOL', 'INDFMT', 'DATAFMT', 'POPSRC', 'DATAFQTR', 'DATACQTR', 'CURCDQ', 'COSTAT'], \n",
    "                  inplace=True)\n",
    "    \n",
    "  def clean_ff4(self):\n",
    "    self.ff4['monthid'] = (self.ff4['DATEFF'].dt.year-1975)*12 + self.ff4['DATEFF'].dt.month\n",
    "    self.fact = self.ff4.copy()\n",
    "    \n",
    "  def illiquidity_filter(self):\n",
    "    self.crsp = self.crsp[self.crsp['PRC'] >= 5]\n",
    "    self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n",
    "    tmp = {}\n",
    "    grp = self.crsp[(self.crsp['month'] == 1) & (self.crsp['MKTCAP'] >= 100000000)].groupby('year')\n",
    "    for yr, group in grp:\n",
    "      tmp[yr] = list(group['PERMNO'])\n",
    "    liquidity = self.crsp.groupby(['year'])['PERMNO'].transform(lambda x: x.isin(tmp[x.name]))\n",
    "    self.crsp = self.crsp[liquidity]\n",
    "    \n",
    "  def merge_data(self):\n",
    "    lhs = self.crsp\n",
    "    rhs = self.comp\n",
    "    self.data = sqldf(\"SELECT a.*, b.* \\\n",
    "                       FROM lhs as a \\\n",
    "                       INNER JOIN rhs as b \\\n",
    "                       ON a.PERMNO = b.LPERMNO and a.monthid >= b.qtrid + 4 and a.monthid <= b.qtrid + 6\")\n",
    "    self.data.drop_duplicates(subset=['PERMNO', 'monthid'], keep='last', inplace=True)\n",
    "    self.data = self.data.loc[:,~self.data.columns.duplicated()].copy()  # remove duplicate col\n",
    "    self.data = pd.merge(self.data, self.ff4, on='monthid')\n",
    "  \n",
    "  def gen_factors(self):\n",
    "    for factor, func in self.factors.items():\n",
    "      try:\n",
    "        self.fact[factor] = func(self.data)\n",
    "      except Exception as e:\n",
    "        print(f\"Error generating {factor=}: {e}\")\n",
    "        print(f\"SKIPPING THIS FACTOR\")\n",
    "    self.fact = pd.merge(self.fact, self.data[['monthid','RET']], on='monthid')\n",
    "  \n",
    "  def fama_macbeth(self):\n",
    "    for factor in self.factors:\n",
    "      try:\n",
    "        fmb = self.fact[['monthid','RET',factor,'SMB','HML','MKTRF','UMD']].copy()\n",
    "        fmb.dropna(inplace=True)\n",
    "        result = fama_macbeth(fmb,'monthid','RET',[factor,'SMB','HML','MKTRF','UMD'],intercept=True)\n",
    "        self.factor_t[factor] = fm_summary(result).loc[factor, 'tstat']\n",
    "      except Exception as e:\n",
    "        print(f\"Error running Fama Macbeth on {factor=}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kitty\\AppData\\Local\\Temp\\ipykernel_34484\\1897533066.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n",
      "C:\\Users\\kitty\\AppData\\Local\\Temp\\ipykernel_34484\\395935338.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  annual_data['oca'] = annual_data['oc'] / annual_data['AT']\n",
      "C:\\Users\\kitty\\AppData\\Local\\Temp\\ipykernel_34484\\395935338.py:279: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  annual_data['ioca'] = annual_data.groupby('year')['oca'].transform(yearly_winsorize)\n",
      "C:\\Users\\kitty\\AppData\\Local\\Temp\\ipykernel_34484\\395935338.py:280: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  annual_data['ioca'] = annual_data.groupby('industry')['ioca'].transform(lambda x: (x - x.mean()) / x.std())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating factor='Abr1': Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\n",
      "A suitable version of pyarrow or fastparquet is required for parquet support.\n",
      "Trying to import the above resulted in these errors:\n",
      " - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n",
      " - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.\n",
      "SKIPPING THIS FACTOR\n",
      "NAN values for DLC: 6332\n",
      "NAN values for DLC filled: 0 remaining\n",
      "NAN values for DLTT: 5291\n",
      "NAN values for DLTT filled: 0 remaining\n",
      "NAN values for MIB: 18809\n",
      "NAN values for MIB filled: 0 remaining\n",
      "NAN values for PSTK: 9007\n",
      "NAN values for PSTK filled: 0 remaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kitty\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\arraylike.py:396: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAN values for IVAO: 21261\n",
      "NAN values for IVAO filled: 0 remaining\n",
      "NAN values for DLTT: 5291\n",
      "NAN values for DLTT filled: 0 remaining\n",
      "NAN values for DLC: 6332\n",
      "NAN values for DLC filled: 0 remaining\n",
      "NAN values for PSTK: 9007\n",
      "NAN values for PSTK filled: 0 remaining\n",
      "Error running Fama Macbeth on factor='Abr1': \"['Abr1'] not in index\"\n"
     ]
    }
   ],
   "source": [
    "assets = Assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>EXCHCD</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>monthid</th>\n",
       "      <th>...</th>\n",
       "      <th>OIADPQ</th>\n",
       "      <th>PSTKQ</th>\n",
       "      <th>SALEQ</th>\n",
       "      <th>qtrid</th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>4246.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.250</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10016</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.250</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>13729.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>5.733</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.084</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.125</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>3.179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.521</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.500</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>7219.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>10.677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.031</td>\n",
       "      <td>271</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.250</td>\n",
       "      <td>-0.129771</td>\n",
       "      <td>8872.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>5.293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.964</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>92284</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836</td>\n",
       "      <td>1.01</td>\n",
       "      <td>20.347</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>92567</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.375</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>24677.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.400</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>92639</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.875</td>\n",
       "      <td>-0.130319</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>5.085</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.231</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>92655</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.625</td>\n",
       "      <td>-0.114035</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.164</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>93201</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.500</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>11839.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>138</td>\n",
       "      <td>...</td>\n",
       "      <td>5.845</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.319</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO                        DATE  SHRCD  EXCHCD     PRC       RET  \\\n",
       "0         10002  1998-01-30 00:00:00.000000   11.0     3.0  25.000  0.020408   \n",
       "1         10016  1998-01-30 00:00:00.000000   11.0     3.0  13.250  0.009524   \n",
       "2         10019  1998-01-30 00:00:00.000000   11.0     3.0  16.125  0.040323   \n",
       "3         10025  1998-01-30 00:00:00.000000   11.0     3.0  33.500  0.085020   \n",
       "4         10026  1998-01-30 00:00:00.000000   11.0     3.0  14.250 -0.129771   \n",
       "...         ...                         ...    ...     ...     ...       ...   \n",
       "1242503   92284  1986-06-30 00:00:00.000000   11.0     3.0  16.000  0.049180   \n",
       "1242504   92567  1986-06-30 00:00:00.000000   11.0     3.0  14.375  0.017699   \n",
       "1242505   92639  1986-06-30 00:00:00.000000   10.0     3.0  40.875 -0.130319   \n",
       "1242506   92655  1986-06-30 00:00:00.000000   11.0     3.0  12.625 -0.114035   \n",
       "1242507   93201  1986-06-30 00:00:00.000000   11.0     3.0  15.500 -0.088235   \n",
       "\n",
       "          SHROUT  year  month  monthid  ...  OIADPQ PSTKQ    SALEQ  qtrid  \\\n",
       "0         4246.0  1998      1      277  ...   2.154  0.00    7.250    273   \n",
       "1        13729.0  1998      1      277  ...   5.733  0.00   38.084    273   \n",
       "2         8205.0  1998      1      277  ...   3.179  0.00   25.521    273   \n",
       "3         7219.0  1998      1      277  ...  10.677  0.00  198.031    271   \n",
       "4         8872.0  1998      1      277  ...   5.293  0.00   62.964    273   \n",
       "...          ...   ...    ...      ...  ...     ...   ...      ...    ...   \n",
       "1242503   9064.0  1986      6      138  ...   1.836  1.01   20.347    132   \n",
       "1242504  24677.0  1986      6      138  ...   2.257  0.00   84.400    132   \n",
       "1242505   5486.0  1986      6      138  ...   5.085  0.00   14.231    132   \n",
       "1242506  15167.0  1986      6      138  ...   2.016  0.00   32.164    132   \n",
       "1242507  11839.0  1986      6      138  ...   5.845  0.00   44.319    132   \n",
       "\n",
       "            DATEFF     SMB     HML   MKTRF      RF     UMD  \n",
       "0       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "1       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "2       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "3       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "4       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "...            ...     ...     ...     ...     ...     ...  \n",
       "1242503 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242504 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242505 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242506 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242507 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "\n",
       "[1242508 rows x 36 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "      <th>monthid</th>\n",
       "      <th>epq1</th>\n",
       "      <th>ioca</th>\n",
       "      <th>ra26</th>\n",
       "      <th>...</th>\n",
       "      <th>Re1</th>\n",
       "      <th>dRoe1</th>\n",
       "      <th>dRoa1</th>\n",
       "      <th>rnaq1</th>\n",
       "      <th>atoq1</th>\n",
       "      <th>dNoa</th>\n",
       "      <th>Nsi</th>\n",
       "      <th>dNca</th>\n",
       "      <th>dFnl</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.231061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.337349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.136564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.215447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.143199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.109665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.076239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.135851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026332</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.243252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            DATEFF     SMB     HML   MKTRF      RF     UMD  monthid      epq1  \\\n",
       "0       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "1       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "2       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "3       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "4       1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1 -0.026479   \n",
       "...            ...     ...     ...     ...     ...     ...      ...       ...   \n",
       "1242503 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242504 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242505 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242506 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "1242507 2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552  0.032500   \n",
       "\n",
       "             ioca      ra26  ...       Re1     dRoe1    dRoa1     rnaq1  \\\n",
       "0       -0.039104       NaN  ...       NaN       NaN      NaN       NaN   \n",
       "1       -0.039104       NaN  ...       NaN       NaN      NaN       NaN   \n",
       "2       -0.039104       NaN  ...       NaN       NaN      NaN       NaN   \n",
       "3       -0.039104       NaN  ...       NaN       NaN      NaN       NaN   \n",
       "4       -0.039104       NaN  ...       NaN       NaN      NaN       NaN   \n",
       "...           ...       ...  ...       ...       ...      ...       ...   \n",
       "1242503  0.046925 -0.016938  ... -0.026332 -0.019447 -0.00936  0.001423   \n",
       "1242504  0.046925 -0.016938  ... -0.026332 -0.019447 -0.00936  0.001423   \n",
       "1242505  0.046925 -0.016938  ... -0.026332 -0.019447 -0.00936  0.001423   \n",
       "1242506  0.046925 -0.016938  ... -0.026332 -0.019447 -0.00936  0.001423   \n",
       "1242507  0.046925 -0.016938  ... -0.026332 -0.019447 -0.00936  0.001423   \n",
       "\n",
       "            atoq1      dNoa       Nsi      dNca      dFnl       RET  \n",
       "0             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.231061  \n",
       "1             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.337349  \n",
       "2             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.333333  \n",
       "3             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.136564  \n",
       "4             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.215447  \n",
       "...           ...       ...       ...       ...       ...       ...  \n",
       "1242503 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.143199  \n",
       "1242504 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.109665  \n",
       "1242505 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.076239  \n",
       "1242506 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.135851  \n",
       "1242507 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.243252  \n",
       "\n",
       "[1242508 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epq1': 4.354950149287537,\n",
       " 'ioca': 6.725643404952385,\n",
       " 'ra26': 2.2393226794162655,\n",
       " 'e11': -3.832979499651745,\n",
       " 'Re1': -0.37614028760115015,\n",
       " 'dRoe1': -2.3516788105980737,\n",
       " 'dRoa1': -2.6461568816234426,\n",
       " 'rnaq1': -4.831482227198306,\n",
       " 'atoq1': 5.357203182042189,\n",
       " 'dNoa': 0.616490622745105,\n",
       " 'Nsi': 7.897841745737835,\n",
       " 'dNca': -7.197752976581749,\n",
       " 'dFnl': -4.05335643742095}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.factor_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Assets at 0x11f5efdbf10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets.fact.to_csv('assets.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
