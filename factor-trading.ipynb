{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from pandasql import sqldf\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from finance_byu.fama_macbeth import fama_macbeth, fm_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRSP = pd.read_sas('crsp.sas7bdat', encoding='latin-1') #fp3v1\n",
    "COMP = pd.read_sas('comp.sas7bdat', encoding='latin-1') #fp3v2\n",
    "FF4 = pd.read_sas('ff4data.sas7bdat', encoding='latin-1')\n",
    "COMP_ANNUAL = pd.read_sas('comp_annual.sas7bdat', encoding='latin-1') # fp3v3\n",
    "INDUSTRY =  pd.read_csv('industries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zero(df, var):\n",
    "    temp = df[var].isna().sum()\n",
    "    df[var].fillna(0, inplace=True)\n",
    "    print(\"NAN values for \" + str(var) + \": \" + str(temp))\n",
    "    temp = df[var].isna().sum()\n",
    "    print(\"NAN values for \" + str(var) + \" filled: \" + str(temp) + \" remaining\")\n",
    "\n",
    "def calculate_credit_metrics(compustat_data):\n",
    "    credit_metrics_df = pd.DataFrame()\n",
    "\n",
    "    # Rename \n",
    "    credit_metrics_df[\"Total_Assets\"] = compustat_data[\"AT\"]\n",
    "    credit_metrics_df[\"Current_Liabilities\"] = compustat_data[\"LCO\"]\n",
    "    credit_metrics_df[\"Long_Term_Debt\"] = compustat_data[\"DLTT\"]\n",
    "    credit_metrics_df[\"Total_Liabilities\"] = compustat_data[\"LT\"]\n",
    "    credit_metrics_df[\"Preferred_Stock\"] = compustat_data[\"PSTK\"]\n",
    "    credit_metrics_df[\"Interest_Expense\"] = compustat_data[\"XINT\"]\n",
    "    credit_metrics_df[\"Cash_Short_Term_Investments\"] = compustat_data[\"CHE\"]\n",
    "    credit_metrics_df[\"Net_Income\"] = compustat_data[\"NI\"]\n",
    "    credit_metrics_df[\"Inventory\"] = compustat_data[\"INVT\"]\n",
    "    credit_metrics_df[\"Total_Equity\"] = compustat_data[\"CEQ\"]\n",
    "\n",
    "    # Calculate financial ratios\n",
    "    credit_metrics_df[\"Debt_Equity_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Debt_Ratio\"] = credit_metrics_df[\"Total_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Current_Ratio\"] = credit_metrics_df[\"Current_Liabilities\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Quick_Ratio\"] = (credit_metrics_df[\"Current_Liabilities\"] - credit_metrics_df[\"Inventory\"]) / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Interest_Coverage_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Interest_Expense\"]\n",
    "    credit_metrics_df[\"Return_On_Assets\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Return_On_Equity\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Equity\"]\n",
    "    credit_metrics_df[\"Asset_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Total_Assets\"]\n",
    "    credit_metrics_df[\"Inventory_Turnover_Ratio\"] = credit_metrics_df[\"Net_Income\"] / credit_metrics_df[\"Inventory\"]\n",
    "\n",
    "    return credit_metrics_df\n",
    "\n",
    "def calculate_credit_score(credit_metrics_df):\n",
    "    # Define weights for each financial metric\n",
    "    weights = {\n",
    "        \"Debt_Equity_Ratio\": 0.2,\n",
    "        \"Debt_Ratio\": 0.1,\n",
    "        \"Current_Ratio\": 0.1,\n",
    "        \"Quick_Ratio\": 0.1,\n",
    "        \"Interest_Coverage_Ratio\": 0.1,\n",
    "        \"Return_On_Assets\": 0.1,\n",
    "        \"Return_On_Equity\": 0.1,\n",
    "        \"Asset_Turnover_Ratio\": 0.1,\n",
    "        \"Inventory_Turnover_Ratio\": 0.1\n",
    "    }\n",
    "\n",
    "    # Calculate the weighted sum of normalized metrics\n",
    "    credit_score = (credit_metrics_df * pd.Series(weights)).sum(axis=1)\n",
    "\n",
    "    return credit_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Factors:\n",
    "  @staticmethod\n",
    "  def _create_hedge_portfolio(data: pd.DataFrame, factor_col: str, q=10, direction=1) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a hedge portfolio, using D10 - D1 returns by default.\n",
    "\n",
    "    Args:\n",
    "      data (pd.DataFrame): Data, must contain columns ['monthid', 'RET', factor_col]\n",
    "      factor_col (str): Name of factor column, i.e. ep1\n",
    "      q (int, optional): Defaults to deciles (10).\n",
    "      direction (int, optional): Either 1 or -1. If 1, we do High - Low. Otherwise, Low - High.\n",
    "\n",
    "    Returns: Return of hedge portfolio at each monthid (i.e. the factor)\n",
    "    \"\"\"\n",
    "    factor = []\n",
    "    index = []  # monthid - 1\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp[factor_col].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    for monthid, mdata in mth_grp:\n",
    "      # TODO: can add value weighting of returns here if anyone needs it\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == q-1]['RET'].mean()\n",
    "      factor.append(direction * (d10 - d1))\n",
    "      index.append(monthid - 1)\n",
    "    return pd.DataFrame(factor, index=index)\n",
    "  \n",
    "  @staticmethod\n",
    "  def dNoa(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    # annual_data = COMP_ANNUAL\n",
    "    fill_zero(annual_data, 'DLC')\n",
    "    fill_zero(annual_data, 'DLTT')\n",
    "    fill_zero(annual_data, 'MIB')\n",
    "    fill_zero(annual_data, 'PSTK')\n",
    "\n",
    "    operating_assets = annual_data[\"AT\"] - annual_data[\"CHE\"]\n",
    "    operating_liabilities = annual_data[\"AT\"] - annual_data[\"DLC\"] - annual_data[\"DLTT\"] - annual_data[\"MIB\"] - annual_data[\"PSTK\"] - annual_data[\"CEQ\"]\n",
    "\n",
    "    Noa = operating_assets - operating_liabilities\n",
    "\n",
    "    lagged_total_assets = annual_data[\"AT\"].shift(1)  # 1-year-lagged total assets\n",
    "    dNoa = (Noa - Noa.shift(1)) / lagged_total_assets\n",
    "\n",
    "    annual_data[\"dNoa\"] = dNoa\n",
    "    annual_data[\"dNoa\"].fillna(0, inplace=True)\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNoa \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNoa'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def Nsi(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "\n",
    "    annual_data[\"CSHO_t_minus_1_adjusted\"] = annual_data[\"CSHO\"] * annual_data[\"AJEX\"]\n",
    "\n",
    "    test_shifted = annual_data.shift(periods=1)\n",
    "    annual_data[\"CSHO_t_minus_2_adjusted\"] = test_shifted[\"CSHO\"] * test_shifted[\"AJEX\"]\n",
    "\n",
    "    annual_data[\"Nsi_u\"] = np.log(annual_data[\"CSHO_t_minus_1_adjusted\"] / annual_data[\"CSHO_t_minus_2_adjusted\"])\n",
    "    annual_data[\"Nsi_u\"].fillna(0, inplace=True)\n",
    "\n",
    "    annual_data[\"Nsi\"] = np.where(annual_data[\"Nsi_u\"] < 0, np.where(annual_data[\"Nsi_u\"] < annual_data[\"Nsi_u\"].quantile(0.5), 1, 2),\n",
    "                             np.where(annual_data[\"Nsi_u\"] == 0, 3,\n",
    "                                      np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.1), 4,\n",
    "                                               np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.2), 5,\n",
    "                                                        np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.3), 6,\n",
    "                                                                 np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.4), 7,\n",
    "                                                                          np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.5), 8,\n",
    "                                                                                   np.where(annual_data[\"Nsi_u\"] <= annual_data[\"Nsi_u\"].quantile(0.6), 9, 10))))))))\n",
    "    annual_data[\"Nsi\"]\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.Nsi \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Nsi'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dNca(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"IVAO\")\n",
    "\n",
    "    annual_data[\"Nca\"] = annual_data[\"AT\"] - annual_data[\"ACT\"] - annual_data[\"IVAO\"]\n",
    "    annual_data[\"dNca_o\"] = annual_data[\"Nca\"].diff()\n",
    "    annual_data[\"dNca_o\"].fillna(0, inplace=True)\n",
    "\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dNca\"] = annual_data[\"dNca_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dNca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dNca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def dFnl(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    fill_zero(annual_data, \"DLTT\")\n",
    "    fill_zero(annual_data, \"DLC\")\n",
    "    fill_zero(annual_data, \"PSTK\")\n",
    "\n",
    "    annual_data[\"Fnl\"] = annual_data[\"DLTT\"] + annual_data[\"DLC\"] + annual_data[\"PSTK\"]\n",
    "    annual_data[\"dFnl_o\"] = annual_data[\"Fnl\"].diff()\n",
    "    annual_data[\"dFnl_o\"].fillna(0, inplace=True)\n",
    "    total_assets_t_minus_2 = annual_data['AT'].iloc[-3]\n",
    "\n",
    "    annual_data[\"dFnl\"] = annual_data[\"dFnl_o\"] / total_assets_t_minus_2\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.dFnl \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['dFnl'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "  @staticmethod\n",
    "  def creditrisk(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    \n",
    "    credit_metrics = calculate_credit_metrics(annual_data)\n",
    "    credit_score = calculate_credit_score(credit_metrics)\n",
    "    annual_data[\"cdrk\"] = credit_score\n",
    "\n",
    "    data = sqldf(\"SELECT a.*, b.cdrk \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['cdrk'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def epq1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data = data[data['IBQ'] >= 0]\n",
    "    data['Epq1'] = data['IBQ'] * 1000000 / data['MKTCAP']\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['Epq1'].transform(lambda x: pd.qcut(x, 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d1 - d10)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ioca(data):\n",
    "    CPI = pd.read_csv('cpi.csv')\n",
    "    g = .10\n",
    "    d = .15\n",
    "    factor = []\n",
    "    annual_data = sqldf(\"SELECT a.*, b.* \\\n",
    "                            FROM COMP_ANNUAL as a \\\n",
    "                            INNER JOIN INDUSTRY as b \\\n",
    "                            ON a.SIC >= b.lhs and a.SIC <= b.rhs\")\n",
    "    annual_data['year'] = annual_data['FYEAR'].astype(int)\n",
    "    annual_data['LPERMNO'] = annual_data['LPERMNO'].astype(int)\n",
    "    annual_data['XSGA'].fillna(0, inplace=True)\n",
    "    annual_data = pd.merge(annual_data, CPI, on='year')\n",
    "    annual_data.sort_values(by=['LPERMNO', 'year', 'XSGA'], inplace=True)\n",
    "    annual_data.drop_duplicates(subset=['LPERMNO', 'year'], keep='last', inplace=True)\n",
    "    grouped = annual_data.groupby('LPERMNO')\n",
    "    oc = []\n",
    "    for _, grp in grouped:\n",
    "      prev = None\n",
    "      for _, row in grp.iterrows():\n",
    "        if prev == None:\n",
    "          prev = row['XSGA'] / (g+d)\n",
    "        else:\n",
    "          prev = (1 - d) * prev + row['XSGA'] / row['CPI']\n",
    "        oc.append(prev)\n",
    "    annual_data['oc'] = oc\n",
    "    annual_data = annual_data[(annual_data['oc'] > 0) & (annual_data['AT'] > 0)]\n",
    "    annual_data['oca'] = annual_data['oc'] / annual_data['AT']\n",
    "    def yearly_winsorize(srs):\n",
    "      p1, p99 = np.nanpercentile(srs, [1, 99])\n",
    "      return np.clip(srs, p1, p99)\n",
    "    annual_data['ioca'] = annual_data.groupby('year')['oca'].transform(yearly_winsorize)\n",
    "    annual_data['ioca'] = annual_data.groupby('industry')['ioca'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "    data = sqldf(\"SELECT a.*, b.ioca \\\n",
    "                  FROM data as a \\\n",
    "                  INNER JOIN annual_data as b \\\n",
    "                  ON a.PERMNO = b.LPERMNO and \\\n",
    "                  ((a.year = b.year and a.month >= 7) or \\\n",
    "                    (a.year = b.year + 1 and a.month <= 6))\")\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['rank'] = mth_grp['ioca'].transform(lambda x: pd.qcut(x.rank(method='first'), 10, labels=False))\n",
    "    for _, mdata in mth_grp:\n",
    "      d1 = mdata[mdata['rank'] == 0]['RET'].mean()\n",
    "      d10 = mdata[mdata['rank'] == 9]['RET'].mean()\n",
    "      factor.append(d10 - d1)\n",
    "    return factor\n",
    "  \n",
    "  @staticmethod\n",
    "  def ra26(data):\n",
    "    factor = []\n",
    "    data = data.sort_values(['PERMNO','monthid'])\n",
    "    datagrp = data.groupby('PERMNO')\n",
    "    for _, grp in datagrp:\n",
    "      for mid in grp['monthid']:\n",
    "        tm = grp[grp['monthid'].isin([mid - 24, mid - 36, mid - 48, mid - 60])]\n",
    "        if (len(tm) < 4):\n",
    "          factor.append(np.NaN)\n",
    "        else:\n",
    "          factor.append(tm['RET'].mean())\n",
    "    data['ra26'] = factor\n",
    "    return Factors._create_hedge_portfolio(data, 'ra26')\n",
    "\n",
    "  @staticmethod\n",
    "  def Abr1(data):\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "\n",
    "    # RET_DAILY = pd.read_sas('ret_daily.sas7bdat', encoding='latin-1')  sas is SLOW\n",
    "    ret_daily = pd.read_parquet(\"ret_daily.parquet\")\n",
    "    vwret = pd.read_sas('us_vwret.sas7bdat', encoding='latin-1').set_index(\"date\")\n",
    "\n",
    "    ret_daily[\"monthid\"] = (ret_daily.DATE.dt.year-1975)*12 + ret_daily.DATE.dt.month\n",
    "\n",
    "    stock_returns = ret_daily.set_index([\"PERMNO\", \"DATE\"]).sort_index()\n",
    "    del ret_daily  # save memory\n",
    "    # faster to pivot first and then do the operations, rather than doing a groupby\n",
    "    stock_returns = stock_returns.pivot_table(values=\"RET\", columns=\"PERMNO\", index=\"DATE\")\n",
    "    stock_returns = stock_returns.sub(vwret.VWRETD, axis=0)  # return over market\n",
    "\n",
    "    # get all 4-period returns from T-3 to T+1\n",
    "    stock_returns = stock_returns.rolling(4).sum().shift(-1)\n",
    "    stock_returns = pd.DataFrame(stock_returns.stack())\n",
    "    stock_returns = stock_returns.rename(columns={0:\"Abr\"})\n",
    "\n",
    "    # Merge on RDQ date so we only have the returns around earnings date\n",
    "    rdqs = data[[\"PERMNO\", \"RDQ\"]].dropna()\n",
    "    rdqs.RDQ = pd.to_datetime(rdqs.RDQ)\n",
    "    rdqs = rdqs.drop_duplicates()\n",
    "    rdqs = rdqs.merge(stock_returns, left_on=[\"RDQ\", \"PERMNO\"], right_index=True, how=\"left\")\n",
    "    del stock_returns  # save memory\n",
    "    # This is the date we use to calculate the monthid to avoid lookahead bias,\n",
    "    # since Abr is calculated using RDQ-3 to RDQ+1 returns.\n",
    "    rdqs[\"RDQ+1\"] = rdqs.RDQ + pd.offsets.BDay(1)\n",
    "    rdqs[\"monthid\"] = (rdqs[\"RDQ+1\"].dt.year-1975)*12 + rdqs[\"RDQ+1\"].dt.month\n",
    "\n",
    "    rdqs = rdqs.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # duplicates can occur where RDQ is in the same month. We drop the first month-PERMNO duplicate\n",
    "    rdqs = rdqs[~rdqs.index.duplicated(keep=\"last\")]\n",
    "\n",
    "    final = pd.DataFrame(index=data.set_index([\"PERMNO\", \"monthid\"]).index).sort_index()\n",
    "    final[\"Abr1\"] = rdqs.Abr\n",
    "    # forward fill only 6 months to avoid stale data\n",
    "    # TODO: could possibly be problems if data skips some monthids, but we still have no lookahead bias, just possible stale data\n",
    "    final = final.groupby(level=0).ffill(limit=6)\n",
    "\n",
    "    data = data.merge(final, how=\"left\", left_on=[\"PERMNO\", \"monthid\"], right_index=True).sort_values(by=['PERMNO', 'monthid'])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"Abr1\", q=10, direction=1)\n",
    "    # return data\n",
    "\n",
    "  @staticmethod\n",
    "  def e11(data):\n",
    "    \"\"\"\n",
    "    Calculate Îµ11 factor (Residual momentum, prior 11-month returns) with 1 month holding period.\n",
    "    \"\"\"\n",
    "    data = data.copy()\n",
    "    \n",
    "    # Get a series of rf indexed by date\n",
    "    rf = data.set_index(\"monthid\")[[\"RF\"]].reset_index().drop_duplicates(subset=\"monthid\")\n",
    "    rf = rf.set_index(\"monthid\").sort_index().RF\n",
    "\n",
    "    # Get xret with each permno in a column\n",
    "    xret = data.loc[:,~data.columns.duplicated()].pivot_table(index=\"monthid\", columns=\"PERMNO\", values=\"RET\").sort_index()\n",
    "    xret = xret.sub(rf, axis=0)\n",
    "\n",
    "    # Get ff data with constant\n",
    "    ff_3 = data[[\"monthid\", \"SMB\", \"HML\", \"MKTRF\"]].drop_duplicates(subset=\"monthid\").set_index(\"monthid\").sort_index()\n",
    "    ff_3 = sm.add_constant(ff_3)\n",
    "\n",
    "    from numpy.linalg import pinv\n",
    "\n",
    "    def last_ff_residual(series: pd.Series, ff: pd.DataFrame) -> float:\n",
    "      \"\"\"Computes FF residuals for a series of excess returns.\n",
    "\n",
    "      Args:\n",
    "        series (pd.DataFrame): rolling excess returns. Must have no null values.\n",
    "        ff (pd.DataFrame): factors, must have overlapping index with `series`. All columns are used as factors. Must have constant column added.\n",
    "\n",
    "      Returns: residual on last date T\n",
    "      \"\"\"\n",
    "      # y = series\n",
    "      x = ff.loc[series.index]\n",
    "      \n",
    "      # ffmodel = sm.OLS(y, x).fit()\n",
    "      # residual_values = ffmodel.resid\n",
    "\n",
    "      # sm.OLS is too slow, do it with linear algebra instead\n",
    "      params = pinv(x).dot(series)\n",
    "\n",
    "      # calculate last residual\n",
    "      t_residual = series.iloc[-1] - x.iloc[-1].dot(params)\n",
    "      \n",
    "      return t_residual\n",
    "\n",
    "    residuals = xret.rolling(window=36, min_periods=36).apply(\n",
    "      lambda series: last_ff_residual(series, ff_3)\n",
    "    )\n",
    "    scaled_residuals = residuals / residuals.rolling(36, min_periods=12).std()\n",
    "\n",
    "    # The time T residual momentum is the sum of residual returns for T-12, T-11, ... T-1\n",
    "    # We do this with a rolling 11 period sum, and then shift down by 1\n",
    "    e11 = scaled_residuals.rolling(11).sum().shift()\n",
    "\n",
    "    # Reshape so the columns are [monthid, PERMNO, e11] and merge into data\n",
    "    e11 = pd.DataFrame(e11.stack()).rename(columns={0: \"e11\"})\n",
    "    data = data.merge(e11, how=\"left\", left_on=[\"monthid\", \"PERMNO\"], right_index=True)\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, \"e11\", q=10, direction=1)\n",
    "\n",
    "  @staticmethod\n",
    "  def Re1(data):\n",
    "    data = data.copy()\n",
    "\n",
    "    ibes_link = pd.read_csv(\"crsp_ibes_link.csv\")  # ibes ticker to PERMNO map  https://wrds-www.wharton.upenn.edu/pages/get-data/linking-suite-wrds/ibes-crsp-link/\n",
    "    ibes_eps = pd.read_csv(\"ibes_eps_estimate.csv\")  # Mean EPS estimates  https://wrds-www.wharton.upenn.edu/pages/get-data/ibes-thomson-reuters/ibes-academic/summary-history/summary-statistics/\n",
    "\n",
    "    ibes_link = ibes_link.dropna()\n",
    "\n",
    "    # Only want USD currency\n",
    "    ibes_eps = ibes_eps[ibes_eps.CURCODE == \"USD\"]\n",
    "\n",
    "    # Get the estimates with the date and permno\n",
    "    eps_est = sqldf(\n",
    "      \"\"\"\n",
    "      select l.permno, e.STATPERS as DATE, e.MEANEST\n",
    "      from ibes_eps e\n",
    "      left join ibes_link l\n",
    "      on e.ticker = l.TICKER and e.STATPERS >= l.sdate and e.STATPERS <= l.edate \n",
    "      \"\"\"\n",
    "    )\n",
    "\n",
    "    # Add monthid\n",
    "    eps_est = eps_est.drop_duplicates(subset=[\"DATE\", \"PERMNO\"])\n",
    "    eps_est.DATE = pd.to_datetime(eps_est.DATE)\n",
    "    eps_est['monthid'] = (eps_est.DATE.dt.year-1975)*12 + eps_est.DATE.dt.month\n",
    "\n",
    "    # Merge close price\n",
    "    eps_est = eps_est.merge(data.set_index([\"monthid\", \"PERMNO\"]).PRC, on=[\"monthid\", \"PERMNO\"])\n",
    "    eps_est = eps_est.set_index([\"PERMNO\", \"monthid\"]).sort_index()\n",
    "\n",
    "    # Calculate factor value for each stock\n",
    "\n",
    "    # TODO: we should make PRC the split adjusted price as our EPS values are split adjusted\n",
    "    re = eps_est.reset_index().set_index(\"monthid\").sort_index().groupby([\"PERMNO\"]).apply(\n",
    "        # 6 period rolling sum of (f_t - f_t-1) / p_t-1, requiring at least 4 consecutive observations\n",
    "        lambda df: ((df.MEANEST - df.MEANEST.shift()) / df.PRC.shift()).rolling(window=6, min_periods=4).sum()\n",
    "    )\n",
    "    eps_est[\"Re1\"] = re\n",
    "    \n",
    "    data = data.merge(eps_est[[\"Re1\"]], how=\"left\", on=[\"monthid\", \"PERMNO\"])\n",
    "    \n",
    "    return Factors._create_hedge_portfolio(data, \"Re1\", q=10, direction=1)\n",
    "  \n",
    "\n",
    "  # D. Investment ==========================================\n",
    "  @staticmethod \n",
    "  def _compute_shifted(data, factor_col, input_col1, input_col2, shift_amt, op='-'):\n",
    "    \"\"\"\n",
    "    for factor calculations that require a shift of data values to avoid\n",
    "    lookahead bias:\n",
    "    Input:\n",
    "      data: DataFrame\n",
    "      factor_col: name of factor to be computed\n",
    "      input_col: name of column used in the factor computation\n",
    "      shift_amt: number of months to lag by for input_col\n",
    "    Return:\n",
    "      a dataframe with cols ['monthid', 'PERMNO', 'factor'] for merge\n",
    "      into the overall data\n",
    "    \"\"\"\n",
    "    permno_grp = data.groupby('PERMNO')\n",
    "    # construct a mini dataframe of shifted values -> (monthid, permno, dRoa1 computed for the relevant month)\n",
    "    factor_values = {'monthid': [], 'PERMNO': [], factor_col:[]}\n",
    "\n",
    "    for _, pdata in permno_grp:\n",
    "      # sort by monthid\n",
    "      pdata = pdata.sort_values('monthid') \n",
    "      # lag Roa to avoid lookahead bias\n",
    "      if (op == '-'):\n",
    "        pdata[factor_col] = pdata[input_col1] - pdata[input_col2].shift(shift_amt)\n",
    "      else:\n",
    "        pdata[factor_col] = pdata[input_col1] / pdata[input_col2].shift(shift_amt)\n",
    "      # add to dataframe\n",
    "      \n",
    "      factor_values['PERMNO'].extend(pdata['PERMNO'].tolist())\n",
    "      factor_values['monthid'].extend(pdata['monthid'].tolist())\n",
    "      factor_values[factor_col].extend(pdata[factor_col].tolist())\n",
    "\n",
    "    factor_values = pd.DataFrame(factor_values)\n",
    "    factor_values['monthid'] = factor_values['monthid'].astype(np.int64)\n",
    "    factor_values['PERMNO'] = factor_values['PERMNO'].astype(np.int64)\n",
    "\n",
    "    return pd.DataFrame(factor_values)\n",
    "    \n",
    "  @staticmethod\n",
    "  def droe1(data):\n",
    "    \"\"\"dRoe: return on equity minus its value from four quarters ago \"\"\"\n",
    "    #   for each month t, sort all stocks into deciles based on their most recent past dRoe\n",
    "    #   monthly decile returns calculated for the current month t\n",
    "\n",
    "    # ROE = NET (RDQ) / Equity (CEQQ)   \n",
    "    data = data.copy()\n",
    "    data['Roe'] = data['NIQ'] / data['CEQQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoe1', input_col1='Roe', input_col2='Roe', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoe1\", q=10)\n",
    "  \n",
    "  @staticmethod\n",
    "  def droa1(data):\n",
    "    \"\"\" droa1 \"is return on assets minus its value from four quarters ago\" \"\"\"\n",
    "    factor = []\n",
    "    data = data.copy()\n",
    "    data['Roa'] = data['NIQ'] / data['ATQ']\n",
    "\n",
    "    # require that earnings announcement date is after the current fiscal quarter end\n",
    "    data = data[~(data['DATADATE'] > data['RDQ'])]\n",
    "    # compute factor values while accounting for lagged inputs\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='dRoa1', input_col1='Roa', input_col2='Roa', shift_amt=12, op='-')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "    # then construct decile portfolios\n",
    "    return Factors._create_hedge_portfolio(data, \"dRoa1\", q=10)\n",
    "\n",
    "  @staticmethod\n",
    "  def rnaq1(data):\n",
    "    \"\"\" Rnaq1: Quarterly return on net operating assets \"\"\"\n",
    "\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='rnaq1', input_col1='OIADPQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'rnaq1')\n",
    "\n",
    "  @staticmethod\n",
    "  def atoq1(data):\n",
    "    \"\"\" atoq1: quarterly sales divided by 1-quarter-lagged Noa \"\"\"\n",
    "    data = data.copy()\n",
    "    # zero out NAs as specified in the paper\n",
    "    fill_na_cols = ['IVAOQ', 'DLCQ', 'DLTTQ', 'MIBQ', 'PSTKQ'] \n",
    "    data[fill_na_cols] = data[fill_na_cols].fillna(0)\n",
    "    # operating assets = ATQ - CHEQ - IVAOQ\n",
    "    data['oa'] = data['ATQ'] - data['CHEQ'] - data['IVAOQ']\n",
    "    # operating liabilities = ATQ - DLCQ - DLTTQ - MIBQ - PSTKQ - CEQQ\n",
    "    data['ol'] = data['ATQ'] - data['DLCQ'] - data['DLTTQ'] - data['MIBQ'] - data['PSTKQ'] - data['CEQQ']\n",
    "    # net operating assets = OA - OL\n",
    "    data['noa'] = data['oa'] - data['ol']\n",
    "\n",
    "    # compute factor values while accounting for lagged inputs - 1 quarter lagged noa\n",
    "    factor_values = Factors._compute_shifted(data, factor_col='atoq1', input_col1='SALEQ', input_col2='noa', shift_amt=4, op='/')\n",
    "    # merge factor values back into the overall data frame\n",
    "    data = data.merge(factor_values, on=[\"monthid\", \"PERMNO\"])\n",
    "\n",
    "    return Factors._create_hedge_portfolio(data, 'atoq1')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add RET_T1 column to data\n",
    "# returns = assets.data[[\"RET\", \"monthid\", \"PERMNO\"]].pivot_table(values=\"RET\", index=\"monthid\", columns=\"PERMNO\")\n",
    "# fwd_ret = returns.shift(-1).stack()\n",
    "# fwd_ret.name = \"RET_T1\"\n",
    "# test = assets.data.merge(fwd_ret, how=\"left\", left_on=[\"monthid\", \"PERMNO\"], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test[test.PERMNO == 10025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assets:\n",
    "  crsp = CRSP.copy()\n",
    "  comp = COMP.copy()\n",
    "  ff4 = FF4.copy()\n",
    "  fact = pd.DataFrame()\n",
    "  data = pd.DataFrame()\n",
    "  train_start = '1975-01-01'\n",
    "  train_end = '2005-12-31'\n",
    "  # test_start = '2006-01-01'\n",
    "  # test_end = '2020-12-31'\n",
    "  factors = {\n",
    "    'epq1': Factors.epq1,\n",
    "    # 'ioca': Factors.ioca,\n",
    "    # 'ra26': Factors.ra26,\n",
    "    # 'e11': Factors.e11,  # comment out for now as this takes ~12min to run\n",
    "    # 'Re1': Factors.Re1,\n",
    "    # 'Abr1': Factors.Abr1,\n",
    "\n",
    "    # D. Investment =====================================\n",
    "    # 'dRoe1': Factors.droe1,\n",
    "    'dRoa1': Factors.droa1,\n",
    "    # 'rnaq1': Factors.rnaq1,\n",
    "    # 'atoq1': Factors.atoq1,\n",
    "\n",
    "    # 'dNoa': Factors.dNoa,\n",
    "    # 'Nsi': Factors.Nsi,\n",
    "    # 'dNca': Factors.dNca,\n",
    "    # 'dFnl' : Factors.dFnl,\n",
    "    # 'creditrisk': Factors.creditrisk\n",
    "  }\n",
    "  factor_fm = pd.DataFrame(columns=['mean','std_error','tstat'])\n",
    "  \n",
    "  def __init__(self, start_date=None):\n",
    "\n",
    "    # Make testing faster by optiSonally limiting dates\n",
    "    if start_date is not None:\n",
    "      self.crsp = self.crsp[self.crsp.DATE >= start_date]\n",
    "      self.comp = self.comp[self.comp.DATADATE >= start_date]\n",
    "\n",
    "    self.clean_crsp()\n",
    "    self.clean_comp()\n",
    "    self.clean_ff4()\n",
    "    self.illiquidity_filter()\n",
    "    \n",
    "    self.merge_data()\n",
    "    self.gen_factors()\n",
    "    self.fama_macbeth()\n",
    "    \n",
    "  def clean_crsp(self):\n",
    "    self.crsp['PERMNO'] = self.crsp['PERMNO'].astype(int)\n",
    "    self.crsp['year'] = self.crsp['DATE'].dt.year\n",
    "    self.crsp['month'] = self.crsp['DATE'].dt.month\n",
    "    self.crsp['monthid'] = (self.crsp['year']-1975)*12 + self.crsp['month']\n",
    "    self.crsp['PRC'] = self.crsp['PRC'].apply(lambda x: x if x > 0 else x * -1)\n",
    "    \n",
    "  def clean_comp(self):\n",
    "    self.comp['qtrid'] = (self.comp['DATADATE'].dt.year-1975)*12 + self.comp['DATADATE'].dt.month\n",
    "    self.comp['LPERMNO'] = self.comp['LPERMNO'].astype(int)\n",
    "    self.comp.drop(columns=['CONSOL', 'INDFMT', 'DATAFMT', 'POPSRC', 'DATAFQTR', 'DATACQTR', 'CURCDQ', 'COSTAT'], \n",
    "                  inplace=True)\n",
    "    \n",
    "  def clean_ff4(self):\n",
    "    self.ff4['monthid'] = (self.ff4['DATEFF'].dt.year-1975)*12 + self.ff4['DATEFF'].dt.month\n",
    "    self.fact = self.ff4.copy()\n",
    "    \n",
    "  def illiquidity_filter(self):\n",
    "    self.crsp = self.crsp[self.crsp['PRC'] >= 5]\n",
    "    self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n",
    "    tmp = {}\n",
    "    grp = self.crsp[(self.crsp['month'] == 1) & (self.crsp['MKTCAP'] >= 100000000)].groupby('year')\n",
    "    for yr, group in grp:\n",
    "      tmp[yr] = list(group['PERMNO'])\n",
    "    liquidity = self.crsp.groupby(['year'])['PERMNO'].transform(lambda x: x.isin(tmp[x.name]))\n",
    "    self.crsp = self.crsp[liquidity]\n",
    "    \n",
    "  def merge_data(self):\n",
    "    lhs = self.crsp\n",
    "    rhs = self.comp\n",
    "    self.data = sqldf(\"SELECT a.*, b.* \\\n",
    "                       FROM lhs as a \\\n",
    "                       INNER JOIN rhs as b \\\n",
    "                       ON a.PERMNO = b.LPERMNO and a.monthid >= b.qtrid + 4 and a.monthid <= b.qtrid + 6\")\n",
    "    self.data.drop_duplicates(subset=['PERMNO', 'monthid'], keep='last', inplace=True)\n",
    "    self.data = self.data.loc[:,~self.data.columns.duplicated()].copy()  # remove duplicate col\n",
    "    self.data = pd.merge(self.data, self.ff4, on='monthid')\n",
    "  \n",
    "  def gen_factors(self):\n",
    "    for factor, func in self.factors.items():\n",
    "      try:\n",
    "        self.fact[factor] = func(self.data)\n",
    "      except Exception as e:\n",
    "        print(f\"Error generating {factor=}: {e}\")\n",
    "        print(f\"SKIPPING THIS FACTOR\")\n",
    "    self.fact = pd.merge(self.fact, self.data[['monthid','RET','PERMNO']], on='monthid')\n",
    "  \n",
    "  def fama_macbeth(self):\n",
    "    for factor, func in self.factors.items():\n",
    "      try:\n",
    "        fmb = self.fact[['DATEFF','monthid','RET',factor,'SMB','HML','MKTRF','UMD']].copy()\n",
    "        fmb = fmb[(fmb['DATEFF'] >= self.train_start) & (fmb['DATEFF'] <= self.train_end)]\n",
    "        fmb.dropna(inplace=True)\n",
    "        result = fama_macbeth(fmb,'monthid','RET',[factor,'SMB','HML','MKTRF','UMD'],intercept=True)\n",
    "        self.factor_fm.loc[factor] = fm_summary(result).loc[factor]\n",
    "      except Exception as e:\n",
    "        print(f\"Error running Fama Macbeth on {factor=}: {e}\")\n",
    "\n",
    "  def gen_factor_betas(self, train_start='1975-01-01', train_end='2005-12-31'):\n",
    "    \"\"\" \n",
    "      testing sample forecasting for linear models\n",
    "    \"\"\"\n",
    "    # initialize a dictionary to store factor betas, where beta columns\n",
    "    # are named {factor}_b\n",
    "    factor_betas = {'PERMNO':[], 'monthid': [], 'alpha':[]}\n",
    "    factor_cols = []\n",
    "    factor_list = list(self.factors.keys())\n",
    "    for factor in self.factors.keys():\n",
    "      factor_b = factor + \"_b\"\n",
    "      # factor_list.append(factor)\n",
    "      factor_cols.append(factor_b)\n",
    "      factor_betas[factor_b] = []\n",
    "\n",
    "    # get coefficients for factors through regression\n",
    "    # combine by stock first, then regress across times\n",
    "    # TODO rolling 36 months\n",
    "    data = self.fact.copy()\n",
    "\n",
    "    # filter data period\n",
    "    data = data[(data['DATEFF'] >= train_start) & (data['DATEFF'] <= train_end)]\n",
    "    permno_grp = data.groupby('PERMNO')\n",
    "\n",
    "    for permno, pdata in permno_grp:\n",
    "      # dropna, TODO consider alternative\n",
    "      pdata = pdata.dropna()\n",
    "      # check number of observations available\n",
    "      if (len(pdata.index) < 12):\n",
    "        continue\n",
    "      # sort by monthid\n",
    "      pdata = pdata.sort_values('monthid') \n",
    "      independents = pdata[factor_list]\n",
    "      # since factors were constructed accounting for lookahead bias (via lags \n",
    "      # when necessary), this step regresses factor values at time t to returns \n",
    "      # at time t\n",
    "      model = linear_model.LinearRegression().fit(independents, pdata[\"RET\"])\n",
    "      # add values to factor coefficients dataframe\n",
    "      factor_betas['PERMNO'].append(pdata['PERMNO'].iloc[0])\n",
    "      factor_betas['monthid'].append(pdata['monthid'].iloc[0])\n",
    "      factor_betas['alpha'].append(model.intercept_)\n",
    "      for i, factor_col in enumerate(factor_cols): \n",
    "        factor_betas[factor_col].append(model.coef_[i])\n",
    "\n",
    "    factor_betas_df = pd.DataFrame(factor_betas)\n",
    "    factor_betas_df.sort_values([\"PERMNO\", \"monthid\"])\n",
    "\n",
    "    return factor_betas_df\n",
    "    \n",
    "  \n",
    "  def score_linear(self):\n",
    "    \"\"\" \n",
    "      score stocks during the out of sample period\n",
    "    \"\"\"\n",
    "    # get factor coefficients from regression\n",
    "    data = self.data.copy()\n",
    "    stock_data = self.data.copy()\n",
    "    factor_betas = self.gen_factor_betas()\n",
    "    factor_list = list(self.factors.keys())\n",
    "    data = pd.merge(data, self.fact, on=[\"PERMNO\", \"monthid\"])\n",
    "    data = pd.merge(data, factor_betas, on=[\"PERMNO\", \"monthid\"])\n",
    "\n",
    "    # add RET_T1 column to data\n",
    "    returns = data[[\"RET\", \"monthid\", \"PERMNO\"]].pivot_table(values=\"RET\", index=\"monthid\", columns=\"PERMNO\")\n",
    "    fwd_ret = returns.shift(-1).stack()\n",
    "    fwd_ret.name = \"RET_T1\"\n",
    "    data = data.merge(how=\"left\", left_on=[\"monthid\", \"PERMNO\"], right_index=True)\n",
    "\n",
    "    # determine holdings based on ranks - for each time point, have a \n",
    "    # list of permnos for top and lowest deciles \n",
    "    # compute returns based on the given formula\n",
    "    data['pre_ret'] = data['alpha']\n",
    "    data['pre_ret'] = data['pre_ret'].fillna(0)\n",
    "    for factor in factor_list:\n",
    "      factor_b = factor+\"_b\"\n",
    "      data['pre_ret'] = data['pre_ret'] + (data[factor] * data[factor_b])\n",
    "    \n",
    "    # rank stocks for each out-of-sample period and thus rebalance at each time\n",
    "    # we want to use the previous month to predict the next, thus use predicted return\n",
    "    # at t-1 for time t's portfolio construction\n",
    "    grouped_data = []\n",
    "    permno_group = data.groupby('PERMNO')\n",
    "    for _, pdata in permno_group:\n",
    "      # sort by monthid, then shift to get t-1 return\n",
    "      pdata = pdata.sort_values([\"monthid\"])\n",
    "      pdata['pre_ret_t1'] = pdata['pre_ret'] # TODO issue here\n",
    "      # pdata['pre_ret_t1'] = pdata['pre_ret'].shift(1)\n",
    "      grouped_data.append(pdata)\n",
    "    # merge back into overall data \n",
    "    data = pd.concat(grouped_data)\n",
    "\n",
    "    # store what permnos to construct the long / short portfolio with \n",
    "    # initialize a dataframe to track decile 10 and 1 portfolios\n",
    "    # rank stocks to deciles based on the values calculated from the predication equation\n",
    "    data['rank'] = data['pre_ret_t1'].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    decile_permnos = {'monthid': [], 'd1_permnos':[],  'd10_permnos': []}\n",
    "    \n",
    "    mth_group = data.groupby('monthid')\n",
    "    for month, mdata in mth_group:\n",
    "      # skipping ones with very little data\n",
    "      if (len(mdata['pre_ret_t1']) < 12):\n",
    "        continue\n",
    "      # construct equal weighted decile portfolios\n",
    "      decile_permnos['monthid'].append(mdata['monthid'].iloc[0])\n",
    "      decile_permnos['d1_permnos'].append(mdata[mdata['rank']==0]['PERMNO'])\n",
    "      decile_permnos['d10_permnos'].append(mdata[mdata['rank']==9]['PERMNO'])\n",
    "\n",
    "    decile_permnos_df = pd.DataFrame(decile_permnos)\n",
    "    decile_permnos_df.sort_values(['monthid'])\n",
    "\n",
    "    # for each time point, we have the permnos of the 1st and 10th decile \n",
    "    # construct equal weighted portfolios \n",
    "    decile_rets = {'monthid': [], 'd1_ret': [], 'd10_ret': []}\n",
    "    mth_groups = stock_data.groupby('monthid')\n",
    "    for _, mdata in mth_groups:\n",
    "      monthid = mdata['monthid'].iloc[0]\n",
    "      # skipping months without data\n",
    "      if not (decile_permnos_df['monthid'].isin([monthid]).any()):\n",
    "        continue\n",
    "      # locate the current monthid's permnos, then filter to those permno and id, and take the mean of the return column \n",
    "      d1_permnos = decile_permnos_df.loc[decile_permnos_df['monthid'] == monthid, 'd1_permnos'].values[0]\n",
    "      d10_permnos = decile_permnos_df.loc[decile_permnos_df['monthid'] == monthid, 'd10_permnos'].values[0]\n",
    "      # filter returns for decile 1 and decile 10 permnos\n",
    "      d1_rets = mdata[mdata['PERMNO'].isin(d1_permnos)]['RET']\n",
    "      d10_rets = mdata[mdata['PERMNO'].isin(d10_permnos)]['RET']\n",
    "      # equal weight d1 and d10 portfolios\n",
    "      decile_rets['monthid'].append(monthid)\n",
    "      decile_rets['d1_ret'].append(-1 * d1_rets.mean()) # short d1 portfolio\n",
    "      decile_rets['d10_ret'].append(d10_rets.mean()) \n",
    "\n",
    "    # return a dataframe of decile returns\n",
    "    decile_rets_df = pd.DataFrame(decile_rets)\n",
    "    decile_rets_df.sort_values([\"monthid\"], inplace=True)\n",
    "    decile_rets_df['d10-d1_ret'] = decile_rets_df['d10_ret'] - decile_rets_df['d1_ret']\n",
    "\n",
    "    capm_ret, ff_ret = Assets.capm_ff_predicted_returns(self.fact.copy())\n",
    "    decile_rets_df['capm_ret'] = capm_ret\n",
    "    decile_rets_df['ff_ret'] = ff_ret\n",
    "    return decile_rets_df\n",
    "\n",
    "\n",
    "  @staticmethod\n",
    "  def capm_ff_predicted_returns(data):\n",
    "    \"\"\" generate CAPM predicted and FF predicted returns\"\"\"\n",
    "    # factors dataframe contains returns and factors for all permnos and monthids\n",
    "    # estimate beta coefficients\n",
    "    data[\"XRET\"] = data[\"RET\"] - data[\"RF\"]\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    # 2 stage regression to get predicted returns \n",
    "    permno_group = data.groupby(\"PERMNO\")\n",
    "    asset_betas = {'PERMNO': [], 'C_MKTRF_b':[], 'F_MKTRF_b': [], 'SMB_b':[], 'HML_b':[], 'UMD_b':[]}\n",
    "    for permno, pdata in permno_group:\n",
    "      # FF factor model to get coefficients\n",
    "      ff_explanatory = pdata[['MKTRF', 'SMB', 'HML', 'UMD']] \n",
    "      ff_explanatory = sm.add_constant(ff_explanatory)\n",
    "      ff_model = sm.OLS(pdata[\"XRET\"], ff_explanatory).fit()\n",
    "      ff_betas = ff_model.params\n",
    "      # CAPM model\n",
    "      capm_explanatory = pdata[['MKTRF']]\n",
    "      capm_explanatory = sm.add_constant(capm_explanatory)\n",
    "      capm_model = sm.OLS(pdata[\"XRET\"], capm_explanatory).fit()\n",
    "      capm_betas = capm_model.params\n",
    "      asset_betas['PERMNO'].append(permno)\n",
    "      asset_betas['C_MKTRF_b'].append(capm_betas['MKTRF'])\n",
    "      asset_betas['F_MKTRF_b'].append(ff_betas['MKTRF'])\n",
    "      asset_betas['SMB_b'].append(ff_betas['SMB'])\n",
    "      asset_betas['HML_b'].append(ff_betas['HML'])\n",
    "      asset_betas['UMD_b'].append(ff_betas['UMD'])\n",
    "\n",
    "    asset_betas_df = pd.DataFrame(asset_betas)\n",
    "    data = pd.merge(data, asset_betas_df, on=[\"PERMNO\"])\n",
    "    month_groups = data.groupby(\"monthid\")\n",
    "\n",
    "    print(asset_betas_df)\n",
    "\t\t# 2nd stage regression is for all assets at each time point\n",
    "    risk_lambdas = {'monthid':[], 'C_MKTRF_l':[], 'F_MKTRF_l': [], 'SMB_l':[], 'HML_l':[], 'UMD_l':[]}\n",
    "    for monthid, mdata in month_groups:\n",
    "      ff_explanatory = mdata[['F_MKTRF_b', 'SMB_b', 'HML_b', 'UMD_b']]\n",
    "      ff_explanatory = sm.add_constant(ff_explanatory)\n",
    "      ff_model = sm.OLS(mdata[\"XRET\"], ff_explanatory).fit()\n",
    "\n",
    "      capm_explanatory = mdata[['C_MKTRF_b']]\n",
    "      capm_explanatory = sm.add_constant(capm_explanatory)\n",
    "      capm_model = sm.OLS(mdata[\"XRET\"], capm_explanatory).fit()\n",
    "\n",
    "      risk_lambdas['monthid'].append(monthid)\n",
    "      risk_lambdas['C_MKTRF_l'].append(capm_model.params['C_MKTRF_b'])\n",
    "      risk_lambdas['F_MKTRF_l'].append(ff_model.params['F_MKTRF_b'])\n",
    "      risk_lambdas['SMB_l'].append(ff_model.params['SMB_b'])\n",
    "      risk_lambdas['HML_l'].append(ff_model.params['HML_b'])\n",
    "      risk_lambdas['UMD_l'].append(ff_model.params['UMD_b'])\n",
    "\n",
    "    # with the risk lambdas, we can predict return\n",
    "    risk_lambdas_df = pd.DataFrame(risk_lambdas)\n",
    "\n",
    "    predict = pd.merge(data, risk_lambdas_df, on=['monthid'])\n",
    "    predict['capm_ret'] = predict['RF'] + (predict['C_MKTRF_b'] * predict['C_MKTRF_l'])\n",
    "    predict['ff_ret'] = predict['RF'] + (predict['SMB_b']*predict['SMB_l']) + (predict['HML_b']*predict['HML_l']) + (predict['UMD_b']*predict['UMD_l'])\n",
    "\n",
    "    return predict['capm_ret'], predict['ff_ret']\n",
    " \n",
    "  def performance_analytics(self, returns, ret_col='RET', benchmark='capm', capm_col='capm_ret', ff_col='ff_ret'):\n",
    "    \"\"\" \n",
    "    takes in a dataframe of returns indexed by monthid:\n",
    "    must include columns:\n",
    "        * RET (for returns to calculate analytics for)\n",
    "        * capm_ret (retruns generated via CAPM model)\n",
    "        * ff_ret (returns generated from FF 4 model)\n",
    "\n",
    "    compute metrics on \"resulting out-of-sample returns over all months in the \n",
    "    out of sample period\"\n",
    "    \"\"\"\n",
    "\n",
    "    raw_ret = returns[ret_col].mean()\n",
    "    capm_ret = returns[capm_col].mean()\n",
    "    ff_ret = returns[ff_col].mean()\n",
    "\n",
    "    if (benchmark=='capm'):\n",
    "      benchmark_col = capm_col\n",
    "      benchmark_ret = capm_ret\n",
    "    else:\n",
    "      benchmark_col = ff_col\n",
    "      benchmark_ret = ff_ret\n",
    "      \n",
    "    # CAPM alpha - difference between capm predicted returns and actual returns\n",
    "    capm_alpha = raw_ret - capm_ret\n",
    "    # 4-Factor alpha - difference between 4 factor predicted returns and actual returns\n",
    "    ff_alpha = raw_ret - ff_ret\n",
    "    # sharpe ratio\n",
    "    sr = (raw_ret - capm_ret) / returns[ret_col].std()\n",
    "    # Information ratio \n",
    "    ir = (raw_ret - benchmark_ret) / (returns[ret_col] - returns[benchmark_col]).std()\n",
    "\n",
    "    analytics = {'raw_return': [raw_ret] , 'sharpe_r':[sr], 'capm_alpha': [capm_alpha], 'ff_alpha': [ff_alpha], 'information_r': [ir]}\n",
    "    return pd.DataFrame(analytics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tz/0pg3_6s57f39kds6_g4kpl680000gn/T/ipykernel_6471/2626803504.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.crsp['MKTCAP'] = self.crsp['PRC'] * self.crsp['SHROUT'] * 1000\n"
     ]
    }
   ],
   "source": [
    "assets = Assets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = assets.data.copy()\n",
    "stock_data = assets.data.copy()\n",
    "factor_betas = assets.gen_factor_betas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Do Fama Macbeth Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack assets to use our cache\n",
    "assets.fact = pd.read_parquet(\"assets.parquet\")\n",
    "\n",
    "assets.factors = {\n",
    "    'epq1': Factors.epq1,\n",
    "    'ioca': Factors.ioca,\n",
    "    'ra26': Factors.ra26,\n",
    "    'e11': Factors.e11,  # comment out for now as this takes ~12min to run\n",
    "    'Re1': Factors.Re1,\n",
    "    'Abr1': Factors.Abr1,\n",
    "\n",
    "    # D. Investment =====================================\n",
    "    'dRoe1': Factors.droe1,\n",
    "    'dRoa1': Factors.droa1,\n",
    "    'rnaq1': Factors.rnaq1,\n",
    "    'atoq1': Factors.atoq1,\n",
    "\n",
    "    'dNoa': Factors.dNoa,\n",
    "    'Nsi': Factors.Nsi,\n",
    "    'dNca': Factors.dNca,\n",
    "    'dFnl' : Factors.dFnl,\n",
    "    # 'creditrisk': Factors.creditrisk\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epq1',\n",
       " 'ioca',\n",
       " 'ra26',\n",
       " 'e11',\n",
       " 'Re1',\n",
       " 'Abr1',\n",
       " 'dRoe1',\n",
       " 'dRoa1',\n",
       " 'rnaq1',\n",
       " 'atoq1',\n",
       " 'dNoa',\n",
       " 'Nsi',\n",
       " 'dNca',\n",
       " 'dFnl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACTORS = list(assets.factors.keys())\n",
    "FACTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets.fama_macbeth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling_exposures = pd.read_parquet(\"rolling_betas.parquet\")\n",
    "\n",
    "# Calculate rolling exposures\n",
    "# copied from ml\n",
    "def calculate_rolling_betas(stock_returns: pd.DataFrame, factor_returns: pd.DataFrame, lookback=36, min_periods=12):\n",
    "    \"\"\"Calculate rolling betas for each stock against each factor individually.\n",
    "\n",
    "    Args:\n",
    "        stock_returns (pd.DataFrame): _description_\n",
    "        factor_returns (pd.DataFrame): _description_\n",
    "        lookback (int, optional): _description_. Defaults to 36.\n",
    "        min_periods (int, optional): _description_. Defaults to 12.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    assert (stock_returns.index == factor_returns.index).all()\n",
    "\n",
    "    betas = {}\n",
    "\n",
    "    rolling_returns = stock_returns.rolling(lookback, min_periods=min_periods)  # returns in shape (rows=monthid, cols=stock)\n",
    "\n",
    "    for f in factor_returns:\n",
    "        print(f\"Computing exposures for {f}...\")\n",
    "\n",
    "        factor_return_series = factor_returns[f]\n",
    "\n",
    "        # beta = cov(stock_return, factor_return) / factor_return.var()\n",
    "        rolling_cov = rolling_returns.cov(factor_return_series)\n",
    "        rolling_betas = rolling_cov.div(factor_return_series.rolling(lookback, min_periods=min_periods).var(), axis=0)\n",
    "        betas[f] = rolling_betas.stack()\n",
    "    \n",
    "    print(f\"Completed all regressions, joining results\")\n",
    "    all_betas = pd.concat(betas.values(), axis=1)\n",
    "    all_betas.columns = betas.keys() \n",
    "    return all_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = data[[\"RET\", \"monthid\", \"PERMNO\"]].pivot_table(values=\"RET\", index=\"monthid\", columns=\"PERMNO\")\n",
    "\n",
    "factors = assets.fact.drop_duplicates(subset=[\"DATEFF\"]).drop(columns=[\"PERMNO\", \"RET\", \"DATEFF\", \"RF\"]).set_index(\"monthid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing exposures for SMB...\n",
      "Computing exposures for HML...\n",
      "Computing exposures for MKTRF...\n",
      "Computing exposures for UMD...\n",
      "Computing exposures for epq1...\n",
      "Computing exposures for ioca...\n",
      "Computing exposures for ra26...\n",
      "Computing exposures for e11...\n",
      "Computing exposures for Abr1...\n",
      "Computing exposures for Re1...\n",
      "Computing exposures for dRoe1...\n",
      "Computing exposures for dRoa1...\n",
      "Computing exposures for rnaq1...\n",
      "Computing exposures for atoq1...\n",
      "Computing exposures for dNoa...\n",
      "Computing exposures for Nsi...\n",
      "Computing exposures for dNca...\n",
      "Computing exposures for dFnl...\n",
      "Completed all regressions, joining results\n"
     ]
    }
   ],
   "source": [
    "rolling_exposures = calculate_rolling_betas(returns, factors, lookback=36, min_periods=12)\n",
    "\n",
    "# rolling_exposures = pd.read_parquet(\"rolling_betas.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>UMD</th>\n",
       "      <th>epq1</th>\n",
       "      <th>ioca</th>\n",
       "      <th>ra26</th>\n",
       "      <th>e11</th>\n",
       "      <th>Abr1</th>\n",
       "      <th>Re1</th>\n",
       "      <th>dRoe1</th>\n",
       "      <th>dRoa1</th>\n",
       "      <th>rnaq1</th>\n",
       "      <th>atoq1</th>\n",
       "      <th>dNoa</th>\n",
       "      <th>Nsi</th>\n",
       "      <th>dNca</th>\n",
       "      <th>dFnl</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>monthid</th>\n",
       "      <th>PERMNO</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">12</th>\n",
       "      <th>10006</th>\n",
       "      <td>1.679308</td>\n",
       "      <td>0.614674</td>\n",
       "      <td>1.139007</td>\n",
       "      <td>-1.707362</td>\n",
       "      <td>-0.105393</td>\n",
       "      <td>0.109047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.610603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.900742</td>\n",
       "      <td>-1.164136</td>\n",
       "      <td>-1.175098</td>\n",
       "      <td>0.434009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10102</th>\n",
       "      <td>1.954394</td>\n",
       "      <td>1.867570</td>\n",
       "      <td>1.670524</td>\n",
       "      <td>-2.060411</td>\n",
       "      <td>-0.304851</td>\n",
       "      <td>-0.117509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.717351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.053599</td>\n",
       "      <td>-0.901849</td>\n",
       "      <td>-2.382929</td>\n",
       "      <td>-3.109737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>1.898073</td>\n",
       "      <td>1.549960</td>\n",
       "      <td>1.493734</td>\n",
       "      <td>-2.289492</td>\n",
       "      <td>-0.856649</td>\n",
       "      <td>-2.235946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.759723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.680210</td>\n",
       "      <td>-3.868717</td>\n",
       "      <td>-1.879660</td>\n",
       "      <td>0.186828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>0.771263</td>\n",
       "      <td>0.558086</td>\n",
       "      <td>1.094370</td>\n",
       "      <td>-0.997185</td>\n",
       "      <td>0.711606</td>\n",
       "      <td>0.955321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679950</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.552862</td>\n",
       "      <td>0.737790</td>\n",
       "      <td>-1.138172</td>\n",
       "      <td>-1.040248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10161</th>\n",
       "      <td>1.119868</td>\n",
       "      <td>1.002363</td>\n",
       "      <td>1.177968</td>\n",
       "      <td>-1.217905</td>\n",
       "      <td>-0.582358</td>\n",
       "      <td>-0.076098</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.767828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.319917</td>\n",
       "      <td>-0.510862</td>\n",
       "      <td>-0.782774</td>\n",
       "      <td>-1.419371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">552</th>\n",
       "      <th>93422</th>\n",
       "      <td>3.076077</td>\n",
       "      <td>-0.084524</td>\n",
       "      <td>1.435013</td>\n",
       "      <td>-1.510296</td>\n",
       "      <td>-0.993870</td>\n",
       "      <td>4.126767</td>\n",
       "      <td>-2.003290</td>\n",
       "      <td>-2.055479</td>\n",
       "      <td>-0.583393</td>\n",
       "      <td>-0.109971</td>\n",
       "      <td>-2.598302</td>\n",
       "      <td>-2.637887</td>\n",
       "      <td>-1.419079</td>\n",
       "      <td>-0.332274</td>\n",
       "      <td>3.812886</td>\n",
       "      <td>-3.577442</td>\n",
       "      <td>-0.647021</td>\n",
       "      <td>0.519884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93423</th>\n",
       "      <td>3.312609</td>\n",
       "      <td>1.810953</td>\n",
       "      <td>2.493631</td>\n",
       "      <td>-1.960793</td>\n",
       "      <td>-2.228965</td>\n",
       "      <td>0.443606</td>\n",
       "      <td>1.532513</td>\n",
       "      <td>-2.624605</td>\n",
       "      <td>-0.093217</td>\n",
       "      <td>-2.253297</td>\n",
       "      <td>-5.689870</td>\n",
       "      <td>-4.353719</td>\n",
       "      <td>-4.634608</td>\n",
       "      <td>0.154103</td>\n",
       "      <td>0.232444</td>\n",
       "      <td>-1.319534</td>\n",
       "      <td>-2.903477</td>\n",
       "      <td>4.069520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93426</th>\n",
       "      <td>2.381135</td>\n",
       "      <td>1.136426</td>\n",
       "      <td>1.476925</td>\n",
       "      <td>-0.980625</td>\n",
       "      <td>-1.141098</td>\n",
       "      <td>1.227748</td>\n",
       "      <td>-0.037411</td>\n",
       "      <td>-0.880351</td>\n",
       "      <td>-0.073059</td>\n",
       "      <td>-0.757526</td>\n",
       "      <td>-1.562708</td>\n",
       "      <td>-2.042546</td>\n",
       "      <td>-1.730868</td>\n",
       "      <td>0.300901</td>\n",
       "      <td>-0.253447</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-1.965552</td>\n",
       "      <td>1.941938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93427</th>\n",
       "      <td>1.572988</td>\n",
       "      <td>0.532561</td>\n",
       "      <td>1.019099</td>\n",
       "      <td>-0.738630</td>\n",
       "      <td>-0.705500</td>\n",
       "      <td>0.660595</td>\n",
       "      <td>0.076590</td>\n",
       "      <td>-1.000012</td>\n",
       "      <td>0.072712</td>\n",
       "      <td>-0.681887</td>\n",
       "      <td>-1.281484</td>\n",
       "      <td>-1.208034</td>\n",
       "      <td>-0.350164</td>\n",
       "      <td>0.942320</td>\n",
       "      <td>0.285429</td>\n",
       "      <td>0.199957</td>\n",
       "      <td>-0.927963</td>\n",
       "      <td>0.927111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93436</th>\n",
       "      <td>1.022571</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>2.116714</td>\n",
       "      <td>-1.160606</td>\n",
       "      <td>-0.942512</td>\n",
       "      <td>-0.111084</td>\n",
       "      <td>0.377209</td>\n",
       "      <td>-1.394423</td>\n",
       "      <td>-0.465998</td>\n",
       "      <td>-1.886929</td>\n",
       "      <td>-5.343435</td>\n",
       "      <td>-4.543288</td>\n",
       "      <td>-4.485997</td>\n",
       "      <td>0.707003</td>\n",
       "      <td>-1.584795</td>\n",
       "      <td>-0.099452</td>\n",
       "      <td>-3.097912</td>\n",
       "      <td>3.443065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1340635 rows Ã 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     SMB       HML     MKTRF       UMD      epq1      ioca  \\\n",
       "monthid PERMNO                                                               \n",
       "12      10006   1.679308  0.614674  1.139007 -1.707362 -0.105393  0.109047   \n",
       "        10102   1.954394  1.867570  1.670524 -2.060411 -0.304851 -0.117509   \n",
       "        10137   1.898073  1.549960  1.493734 -2.289492 -0.856649 -2.235946   \n",
       "        10145   0.771263  0.558086  1.094370 -0.997185  0.711606  0.955321   \n",
       "        10161   1.119868  1.002363  1.177968 -1.217905 -0.582358 -0.076098   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "552     93422   3.076077 -0.084524  1.435013 -1.510296 -0.993870  4.126767   \n",
       "        93423   3.312609  1.810953  2.493631 -1.960793 -2.228965  0.443606   \n",
       "        93426   2.381135  1.136426  1.476925 -0.980625 -1.141098  1.227748   \n",
       "        93427   1.572988  0.532561  1.019099 -0.738630 -0.705500  0.660595   \n",
       "        93436   1.022571  0.601093  2.116714 -1.160606 -0.942512 -0.111084   \n",
       "\n",
       "                    ra26       e11      Abr1       Re1     dRoe1     dRoa1  \\\n",
       "monthid PERMNO                                                               \n",
       "12      10006        NaN       NaN  0.610603       NaN       NaN       NaN   \n",
       "        10102        NaN       NaN  1.717351       NaN       NaN       NaN   \n",
       "        10137        NaN       NaN  0.759723       NaN       NaN       NaN   \n",
       "        10145        NaN       NaN  0.679950       NaN       NaN       NaN   \n",
       "        10161        NaN       NaN  0.767828       NaN       NaN       NaN   \n",
       "...                  ...       ...       ...       ...       ...       ...   \n",
       "552     93422  -2.003290 -2.055479 -0.583393 -0.109971 -2.598302 -2.637887   \n",
       "        93423   1.532513 -2.624605 -0.093217 -2.253297 -5.689870 -4.353719   \n",
       "        93426  -0.037411 -0.880351 -0.073059 -0.757526 -1.562708 -2.042546   \n",
       "        93427   0.076590 -1.000012  0.072712 -0.681887 -1.281484 -1.208034   \n",
       "        93436   0.377209 -1.394423 -0.465998 -1.886929 -5.343435 -4.543288   \n",
       "\n",
       "                   rnaq1     atoq1      dNoa       Nsi      dNca      dFnl  \n",
       "monthid PERMNO                                                              \n",
       "12      10006        NaN       NaN -0.900742 -1.164136 -1.175098  0.434009  \n",
       "        10102        NaN       NaN -1.053599 -0.901849 -2.382929 -3.109737  \n",
       "        10137        NaN       NaN -1.680210 -3.868717 -1.879660  0.186828  \n",
       "        10145        NaN       NaN -0.552862  0.737790 -1.138172 -1.040248  \n",
       "        10161        NaN       NaN -0.319917 -0.510862 -0.782774 -1.419371  \n",
       "...                  ...       ...       ...       ...       ...       ...  \n",
       "552     93422  -1.419079 -0.332274  3.812886 -3.577442 -0.647021  0.519884  \n",
       "        93423  -4.634608  0.154103  0.232444 -1.319534 -2.903477  4.069520  \n",
       "        93426  -1.730868  0.300901 -0.253447 -0.390748 -1.965552  1.941938  \n",
       "        93427  -0.350164  0.942320  0.285429  0.199957 -0.927963  0.927111  \n",
       "        93436  -4.485997  0.707003 -1.584795 -0.099452 -3.097912  3.443065  \n",
       "\n",
       "[1340635 rows x 18 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "epq1     0.001333\n",
       "dRoa1   -0.000118\n",
       "ioca     0.000704\n",
       "ra26     0.000349\n",
       "e11     -0.000442\n",
       "Re1      0.000152\n",
       "Abr1     0.001243\n",
       "dRoe1   -0.000097\n",
       "rnaq1   -0.000462\n",
       "atoq1    0.000614\n",
       "dNoa     0.000188\n",
       "Nsi      0.001401\n",
       "dNca    -0.000566\n",
       "dFnl    -0.000222\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_premia = assets.factor_fm[\"mean\"]\n",
    "factor_premia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum(Factor Premia * Factor Beta) gives us the predicted T+1 return\n",
    "preds = (rolling_exposures[FACTORS] * factor_premia.loc[FACTORS]).sum(axis=1)\n",
    "preds = pd.DataFrame(preds, columns=[\"pred\"])\n",
    "\n",
    "# Get T+1 actual returns\n",
    "returns = data[[\"RET\", \"monthid\", \"PERMNO\"]].pivot_table(values=\"RET\", index=\"monthid\", columns=\"PERMNO\")\n",
    "fwd_ret = returns.shift(-1).stack()\n",
    "fwd_ret.name = \"RET_T1\"\n",
    "\n",
    "# Get RF\n",
    "rf = data.set_index(\"monthid\")[\"RF\"]\n",
    "rf = rf[~rf.index.duplicated()]  # rf indexed by monthid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "# Function to build the portfolio and calculate different performance metrics\n",
    "def portfolio_build(df_pred: pd.DataFrame, model_name: str, actual_t1_returns: pd.Series, rf_month):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "        df_pred: DataFrame indexed by [monthid, permno] with column \"pred\" for predicted T+1 returns\n",
    "        model_name: Str cosmetic name\n",
    "        actual_t1_returns: Series indexed by [monthid, permno] with actual T+1 returns\n",
    "        rf_month: RF returns each month\n",
    "    \"\"\"\n",
    "    actual_t1_returns.name = \"ACTUAL_RET_T1\"\n",
    "\n",
    "    data = df_pred.merge(actual_t1_returns, how=\"left\", left_index=True, right_index=True)\n",
    "\n",
    "    portfolio_ret = []\n",
    "    # index is monthid + 1, since these returns are for the start of the current period to end of next period, so month ending monthid+1\n",
    "    index = []\n",
    "    mth_grp = data.groupby('monthid')\n",
    "    data['pred_rank'] = mth_grp[\"pred\"].transform(lambda x: pd.qcut(x.rank(method=\"first\"), 10, labels=False) if not np.isnan(x).all() else x)  # if statement in case all NaN\n",
    "    for monthid, mdata in mth_grp:\n",
    "      # TODO: can add value weighting of returns here if anyone needs it\n",
    "      d1 = mdata[mdata['pred_rank'] == 0]['ACTUAL_RET_T1'].mean()\n",
    "      d10 = mdata[mdata['pred_rank'] == 9]['ACTUAL_RET_T1'].mean()\n",
    "      portfolio_ret.append(d10 - d1)\n",
    "      index.append(monthid + 1)\n",
    "\n",
    "    # Portfolio returns, indexed by monthid of the return end period\n",
    "    ls_df = pd.DataFrame(portfolio_ret, index=index, columns=[\"ls_ret\"])\n",
    "    \n",
    "    # Calculating cumulative returns\n",
    "    # First we +1 to the returns \n",
    "    # Then we do the cumulative product\n",
    "    ls_df['cumulative_ret']= ls_df['ls_ret'] + 1\n",
    "    ls_df['cumulative_ret'] = ls_df['cumulative_ret'].cumprod()\n",
    "    \n",
    "    # Get mean/std/sharpe ratio for the portfolio\n",
    "    ls_df = pd.merge(ls_df, rf_month, left_index = True, right_index = True)\n",
    "    ls_df['ls_sub_rf'] = ls_df['ls_ret'] - ls_df['RF']\n",
    "    ls_rf = ls_df['RF'].mean()*12\n",
    "    ls_sub_rf_mean = ls_df['ls_sub_rf'].mean()*12\n",
    "    ls_sub_rf_std = ls_df['ls_sub_rf'].std()*math.sqrt(12)\n",
    "    sharpe_ratio = ls_sub_rf_mean/ls_sub_rf_std*math.sqrt(12)\n",
    "    \n",
    "    print(model_name + \" excess return (ann): \" + str(ls_sub_rf_mean))\n",
    "    print(model_name + \" volatility (ann): \" + str(ls_sub_rf_std))\n",
    "    print(model_name + \" sharpe ratio (ann): \" + str(sharpe_ratio))\n",
    "    print()\n",
    "\n",
    "\n",
    "    return ls_df, ls_sub_rf_mean, ls_sub_rf_std, sharpe_ratio, ls_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FM excess return (ann): -0.01899549620801033\n",
      "FM volatility (ann): 0.2485375333743147\n",
      "FM sharpe ratio (ann): -0.26475811601223553\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ls_ret</th>\n",
       "      <th>cumulative_ret</th>\n",
       "      <th>RF</th>\n",
       "      <th>ls_sub_rf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.041892</td>\n",
       "      <td>0.949040</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>-0.045292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.948874</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>-0.004175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.037805</td>\n",
       "      <td>0.913002</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.042005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.029695</td>\n",
       "      <td>0.885891</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>-0.033395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-0.033915</td>\n",
       "      <td>0.851257</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.034015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>0.010868</td>\n",
       "      <td>0.860509</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.010768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-0.039190</td>\n",
       "      <td>0.826785</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.039290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-0.067540</td>\n",
       "      <td>0.770944</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.067640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ls_ret  cumulative_ret      RF  ls_sub_rf\n",
       "13  -0.009464        0.990536  0.0047  -0.014164\n",
       "14  -0.041892        0.949040  0.0034  -0.045292\n",
       "15  -0.000175        0.948874  0.0040  -0.004175\n",
       "16  -0.037805        0.913002  0.0042  -0.042005\n",
       "17  -0.029695        0.885891  0.0037  -0.033395\n",
       "..        ...             ...     ...        ...\n",
       "548 -0.033915        0.851257  0.0001  -0.034015\n",
       "549  0.010868        0.860509  0.0001   0.010768\n",
       "550 -0.039190        0.826785  0.0001  -0.039290\n",
       "551 -0.067540        0.770944  0.0001  -0.067640\n",
       "552 -0.018429        0.756737  0.0001  -0.018529\n",
       "\n",
       "[540 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "portfolio_returns, port_xret, port_vol, port_sharpe, rf = portfolio_build(preds, \"FM\", fwd_ret, rf)\n",
    "portfolio_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_returns.index.name = 'monthid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Analytics for Out of Sample Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthid</th>\n",
       "      <th>ls_ret</th>\n",
       "      <th>cumulative_ret</th>\n",
       "      <th>RF_x</th>\n",
       "      <th>ls_sub_rf</th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF_y</th>\n",
       "      <th>...</th>\n",
       "      <th>dRoe1</th>\n",
       "      <th>dRoa1</th>\n",
       "      <th>rnaq1</th>\n",
       "      <th>atoq1</th>\n",
       "      <th>dNoa</th>\n",
       "      <th>Nsi</th>\n",
       "      <th>dNca</th>\n",
       "      <th>dFnl</th>\n",
       "      <th>RET</th>\n",
       "      <th>PERMNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>1976-01-30</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028716</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.042668</td>\n",
       "      <td>-0.083113</td>\n",
       "      <td>-0.056154</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>-0.049253</td>\n",
       "      <td>0.211039</td>\n",
       "      <td>10006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>1976-01-30</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028716</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.042668</td>\n",
       "      <td>-0.083113</td>\n",
       "      <td>-0.056154</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>-0.049253</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>10102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>1976-01-30</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028716</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.042668</td>\n",
       "      <td>-0.083113</td>\n",
       "      <td>-0.056154</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>-0.049253</td>\n",
       "      <td>0.047297</td>\n",
       "      <td>10137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>1976-01-30</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028716</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.042668</td>\n",
       "      <td>-0.083113</td>\n",
       "      <td>-0.056154</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>-0.049253</td>\n",
       "      <td>0.240602</td>\n",
       "      <td>10145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>-0.009464</td>\n",
       "      <td>0.990536</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>-0.014164</td>\n",
       "      <td>1976-01-30</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028716</td>\n",
       "      <td>-0.043551</td>\n",
       "      <td>-0.006418</td>\n",
       "      <td>-0.042668</td>\n",
       "      <td>-0.083113</td>\n",
       "      <td>-0.056154</td>\n",
       "      <td>-0.082435</td>\n",
       "      <td>-0.049253</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>10153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234234</th>\n",
       "      <td>552</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.143199</td>\n",
       "      <td>93397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234235</th>\n",
       "      <td>552</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>93423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234236</th>\n",
       "      <td>552</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>93426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234237</th>\n",
       "      <td>552</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>93427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234238</th>\n",
       "      <td>552</td>\n",
       "      <td>-0.018429</td>\n",
       "      <td>0.756737</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.018529</td>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.009360</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>93436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234239 rows Ã 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         monthid    ls_ret  cumulative_ret    RF_x  ls_sub_rf      DATEFF  \\\n",
       "0             13 -0.009464        0.990536  0.0047  -0.014164  1976-01-30   \n",
       "1             13 -0.009464        0.990536  0.0047  -0.014164  1976-01-30   \n",
       "2             13 -0.009464        0.990536  0.0047  -0.014164  1976-01-30   \n",
       "3             13 -0.009464        0.990536  0.0047  -0.014164  1976-01-30   \n",
       "4             13 -0.009464        0.990536  0.0047  -0.014164  1976-01-30   \n",
       "...          ...       ...             ...     ...        ...         ...   \n",
       "1234234      552 -0.018429        0.756737  0.0001  -0.018529  2020-12-31   \n",
       "1234235      552 -0.018429        0.756737  0.0001  -0.018529  2020-12-31   \n",
       "1234236      552 -0.018429        0.756737  0.0001  -0.018529  2020-12-31   \n",
       "1234237      552 -0.018429        0.756737  0.0001  -0.018529  2020-12-31   \n",
       "1234238      552 -0.018429        0.756737  0.0001  -0.018529  2020-12-31   \n",
       "\n",
       "            SMB     HML   MKTRF    RF_y  ...     dRoe1     dRoa1     rnaq1  \\\n",
       "0        0.0481  0.0863  0.1216  0.0047  ... -0.028716 -0.043551 -0.006418   \n",
       "1        0.0481  0.0863  0.1216  0.0047  ... -0.028716 -0.043551 -0.006418   \n",
       "2        0.0481  0.0863  0.1216  0.0047  ... -0.028716 -0.043551 -0.006418   \n",
       "3        0.0481  0.0863  0.1216  0.0047  ... -0.028716 -0.043551 -0.006418   \n",
       "4        0.0481  0.0863  0.1216  0.0047  ... -0.028716 -0.043551 -0.006418   \n",
       "...         ...     ...     ...     ...  ...       ...       ...       ...   \n",
       "1234234  0.0489 -0.0151  0.0463  0.0001  ... -0.019447 -0.009360  0.001423   \n",
       "1234235  0.0489 -0.0151  0.0463  0.0001  ... -0.019447 -0.009360  0.001423   \n",
       "1234236  0.0489 -0.0151  0.0463  0.0001  ... -0.019447 -0.009360  0.001423   \n",
       "1234237  0.0489 -0.0151  0.0463  0.0001  ... -0.019447 -0.009360  0.001423   \n",
       "1234238  0.0489 -0.0151  0.0463  0.0001  ... -0.019447 -0.009360  0.001423   \n",
       "\n",
       "            atoq1      dNoa       Nsi      dNca      dFnl       RET  PERMNO  \n",
       "0       -0.042668 -0.083113 -0.056154 -0.082435 -0.049253  0.211039   10006  \n",
       "1       -0.042668 -0.083113 -0.056154 -0.082435 -0.049253  0.198582   10102  \n",
       "2       -0.042668 -0.083113 -0.056154 -0.082435 -0.049253  0.047297   10137  \n",
       "3       -0.042668 -0.083113 -0.056154 -0.082435 -0.049253  0.240602   10145  \n",
       "4       -0.042668 -0.083113 -0.056154 -0.082435 -0.049253  0.218750   10153  \n",
       "...           ...       ...       ...       ...       ...       ...     ...  \n",
       "1234234 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.143199   93397  \n",
       "1234235 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.109665   93423  \n",
       "1234236 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.076239   93426  \n",
       "1234237 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.135851   93427  \n",
       "1234238 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.243252   93436  \n",
       "\n",
       "[1234239 rows x 27 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FF alpha: -0.000669460614559046,  p-value: 4.156754563559955e-58 \n",
      "CAPM alpha: -0.005146722774515812,  p-value: 0.0 \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_return</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>capm_alpha</th>\n",
       "      <th>ff_alpha</th>\n",
       "      <th>information_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.043263</td>\n",
       "      <td>-0.264758</td>\n",
       "      <td>-0.005147</td>\n",
       "      <td>-0.000669</td>\n",
       "      <td>-1.144581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_return  sharpe_ratio  capm_alpha  ff_alpha  information_ratio\n",
       "0    0.043263     -0.264758   -0.005147 -0.000669          -1.144581"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors = assets.fact.copy()\n",
    " \n",
    "# ff alpha \n",
    "data = portfolio_returns\n",
    "data = pd.merge(portfolio_returns, factors[[\"monthid\", \"DATEFF\", \"MKTRF\", \"SMB\", \"HML\", \"UMD\"]], on=[\"monthid\"])\n",
    "y = data[\"ls_sub_rf\"]\n",
    "x = data[[\"MKTRF\", \"SMB\", \"HML\", \"UMD\"]]\n",
    "x = sm.add_constant(x)\n",
    "ff4model = sm.OLS(y,x).fit()\n",
    "ff_alpha = ff4model.params[0]\n",
    "ff_alpha_p = ff4model.pvalues[0]\n",
    "\n",
    "# CAPM alpha\n",
    "x = data[[\"MKTRF\"]]\n",
    "x = sm.add_constant(x)\n",
    "capmmodel = sm.OLS(y,x).fit()\n",
    "capm_alpha = capmmodel.params[0]\n",
    "capm_alpha_p = capmmodel.pvalues[0]\n",
    "\n",
    "print(f\"FF alpha: {ff_alpha},  p-value: {ff_alpha_p} \")\n",
    "print(f\"CAPM alpha: {capm_alpha},  p-value: {capm_alpha_p} \")\n",
    "\n",
    "# information ratio\n",
    "benchmark = (data['MKTRF']+data['RF']).mean()*12\n",
    "port_ret = data['ls_ret'].mean()*12\n",
    "ir = (port_ret - benchmark) / (data['ls_ret'] - (data['MKTRF'] + data['RF'])).std() \n",
    "\n",
    "analytics = {'raw_return': [port_ret], 'sharpe_ratio': [port_sharpe], \n",
    "             'capm_alpha': [capm_alpha], 'ff_alpha':[ff_alpha], 'information_ratio': [ir]}\n",
    "analytics_df = pd.DataFrame(analytics)\n",
    "analytics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERMNO</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CUSIP</th>\n",
       "      <th>SHRCD</th>\n",
       "      <th>EXCHCD</th>\n",
       "      <th>PRC</th>\n",
       "      <th>RET</th>\n",
       "      <th>SHROUT</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>OIADPQ</th>\n",
       "      <th>PSTKQ</th>\n",
       "      <th>SALEQ</th>\n",
       "      <th>qtrid</th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>05978R10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>4246.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.154</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.250</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10016</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>81002230</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.250</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>13729.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.733</td>\n",
       "      <td>0.00</td>\n",
       "      <td>38.084</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10019</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>44950710</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.125</td>\n",
       "      <td>0.040323</td>\n",
       "      <td>8205.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.179</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.521</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10025</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>00103110</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>33.500</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>7219.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.677</td>\n",
       "      <td>0.00</td>\n",
       "      <td>198.031</td>\n",
       "      <td>271</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10026</td>\n",
       "      <td>1998-01-30 00:00:00.000000</td>\n",
       "      <td>46603210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.250</td>\n",
       "      <td>-0.129771</td>\n",
       "      <td>8872.0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>62.964</td>\n",
       "      <td>273</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>-0.0107</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>92284</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>00794210</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>0.049180</td>\n",
       "      <td>9064.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.836</td>\n",
       "      <td>1.01</td>\n",
       "      <td>20.347</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>92567</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>19827410</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.375</td>\n",
       "      <td>0.017699</td>\n",
       "      <td>24677.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.257</td>\n",
       "      <td>0.00</td>\n",
       "      <td>84.400</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>92639</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>90290110</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.875</td>\n",
       "      <td>-0.130319</td>\n",
       "      <td>5486.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.085</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.231</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>92655</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>91324P10</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.625</td>\n",
       "      <td>-0.114035</td>\n",
       "      <td>15167.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32.164</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>93201</td>\n",
       "      <td>1986-06-30 00:00:00.000000</td>\n",
       "      <td>98360410</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.500</td>\n",
       "      <td>-0.088235</td>\n",
       "      <td>11839.0</td>\n",
       "      <td>1986</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5.845</td>\n",
       "      <td>0.00</td>\n",
       "      <td>44.319</td>\n",
       "      <td>132</td>\n",
       "      <td>1986-06-30</td>\n",
       "      <td>-0.0096</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows Ã 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         PERMNO                        DATE     CUSIP  SHRCD  EXCHCD     PRC  \\\n",
       "0         10002  1998-01-30 00:00:00.000000  05978R10   11.0     3.0  25.000   \n",
       "1         10016  1998-01-30 00:00:00.000000  81002230   11.0     3.0  13.250   \n",
       "2         10019  1998-01-30 00:00:00.000000  44950710   11.0     3.0  16.125   \n",
       "3         10025  1998-01-30 00:00:00.000000  00103110   11.0     3.0  33.500   \n",
       "4         10026  1998-01-30 00:00:00.000000  46603210   11.0     3.0  14.250   \n",
       "...         ...                         ...       ...    ...     ...     ...   \n",
       "1242503   92284  1986-06-30 00:00:00.000000  00794210   11.0     3.0  16.000   \n",
       "1242504   92567  1986-06-30 00:00:00.000000  19827410   11.0     3.0  14.375   \n",
       "1242505   92639  1986-06-30 00:00:00.000000  90290110   10.0     3.0  40.875   \n",
       "1242506   92655  1986-06-30 00:00:00.000000  91324P10   11.0     3.0  12.625   \n",
       "1242507   93201  1986-06-30 00:00:00.000000  98360410   11.0     3.0  15.500   \n",
       "\n",
       "              RET   SHROUT  year  month  ...  OIADPQ  PSTKQ    SALEQ qtrid  \\\n",
       "0        0.020408   4246.0  1998      1  ...   2.154   0.00    7.250   273   \n",
       "1        0.009524  13729.0  1998      1  ...   5.733   0.00   38.084   273   \n",
       "2        0.040323   8205.0  1998      1  ...   3.179   0.00   25.521   273   \n",
       "3        0.085020   7219.0  1998      1  ...  10.677   0.00  198.031   271   \n",
       "4       -0.129771   8872.0  1998      1  ...   5.293   0.00   62.964   273   \n",
       "...           ...      ...   ...    ...  ...     ...    ...      ...   ...   \n",
       "1242503  0.049180   9064.0  1986      6  ...   1.836   1.01   20.347   132   \n",
       "1242504  0.017699  24677.0  1986      6  ...   2.257   0.00   84.400   132   \n",
       "1242505 -0.130319   5486.0  1986      6  ...   5.085   0.00   14.231   132   \n",
       "1242506 -0.114035  15167.0  1986      6  ...   2.016   0.00   32.164   132   \n",
       "1242507 -0.088235  11839.0  1986      6  ...   5.845   0.00   44.319   132   \n",
       "\n",
       "            DATEFF     SMB     HML   MKTRF      RF     UMD  \n",
       "0       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "1       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "2       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "3       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "4       1998-01-30 -0.0107 -0.0163  0.0015  0.0043  0.0014  \n",
       "...            ...     ...     ...     ...     ...     ...  \n",
       "1242503 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242504 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242505 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242506 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "1242507 1986-06-30 -0.0096  0.0128  0.0103  0.0052  0.0507  \n",
       "\n",
       "[1242508 rows x 37 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATEFF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>MKTRF</th>\n",
       "      <th>RF</th>\n",
       "      <th>UMD</th>\n",
       "      <th>monthid</th>\n",
       "      <th>epq1</th>\n",
       "      <th>ioca</th>\n",
       "      <th>ra26</th>\n",
       "      <th>...</th>\n",
       "      <th>dRoe1</th>\n",
       "      <th>dRoa1</th>\n",
       "      <th>rnaq1</th>\n",
       "      <th>atoq1</th>\n",
       "      <th>dNoa</th>\n",
       "      <th>Nsi</th>\n",
       "      <th>dNca</th>\n",
       "      <th>dFnl</th>\n",
       "      <th>RET</th>\n",
       "      <th>PERMNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.231061</td>\n",
       "      <td>10006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>10102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>10137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.136564</td>\n",
       "      <td>10145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975-01-31</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>0.0828</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.1382</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.026479</td>\n",
       "      <td>-0.039104</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.109014</td>\n",
       "      <td>-0.018458</td>\n",
       "      <td>-0.090733</td>\n",
       "      <td>-0.033594</td>\n",
       "      <td>0.215447</td>\n",
       "      <td>10161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242503</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.143199</td>\n",
       "      <td>93397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242504</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.109665</td>\n",
       "      <td>93423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242505</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.076239</td>\n",
       "      <td>93426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242506</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.135851</td>\n",
       "      <td>93427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242507</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>-0.0151</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.0232</td>\n",
       "      <td>552</td>\n",
       "      <td>0.032500</td>\n",
       "      <td>0.046925</td>\n",
       "      <td>-0.016938</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>-0.00936</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>-0.018967</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.026051</td>\n",
       "      <td>-0.034905</td>\n",
       "      <td>-0.019750</td>\n",
       "      <td>0.243252</td>\n",
       "      <td>93436</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1242508 rows Ã 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             DATEFF     SMB     HML   MKTRF      RF     UMD  monthid  \\\n",
       "0        1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1   \n",
       "1        1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1   \n",
       "2        1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1   \n",
       "3        1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1   \n",
       "4        1975-01-31  0.1114  0.0828  0.1366  0.0058 -0.1382        1   \n",
       "...             ...     ...     ...     ...     ...     ...      ...   \n",
       "1242503  2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552   \n",
       "1242504  2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552   \n",
       "1242505  2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552   \n",
       "1242506  2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552   \n",
       "1242507  2020-12-31  0.0489 -0.0151  0.0463  0.0001 -0.0232      552   \n",
       "\n",
       "             epq1      ioca      ra26  ...     dRoe1    dRoa1     rnaq1  \\\n",
       "0       -0.026479 -0.039104       NaN  ...       NaN      NaN       NaN   \n",
       "1       -0.026479 -0.039104       NaN  ...       NaN      NaN       NaN   \n",
       "2       -0.026479 -0.039104       NaN  ...       NaN      NaN       NaN   \n",
       "3       -0.026479 -0.039104       NaN  ...       NaN      NaN       NaN   \n",
       "4       -0.026479 -0.039104       NaN  ...       NaN      NaN       NaN   \n",
       "...           ...       ...       ...  ...       ...      ...       ...   \n",
       "1242503  0.032500  0.046925 -0.016938  ... -0.019447 -0.00936  0.001423   \n",
       "1242504  0.032500  0.046925 -0.016938  ... -0.019447 -0.00936  0.001423   \n",
       "1242505  0.032500  0.046925 -0.016938  ... -0.019447 -0.00936  0.001423   \n",
       "1242506  0.032500  0.046925 -0.016938  ... -0.019447 -0.00936  0.001423   \n",
       "1242507  0.032500  0.046925 -0.016938  ... -0.019447 -0.00936  0.001423   \n",
       "\n",
       "            atoq1      dNoa       Nsi      dNca      dFnl       RET  PERMNO  \n",
       "0             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.231061   10006  \n",
       "1             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.337349   10102  \n",
       "2             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.333333   10137  \n",
       "3             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.136564   10145  \n",
       "4             NaN -0.109014 -0.018458 -0.090733 -0.033594  0.215447   10161  \n",
       "...           ...       ...       ...       ...       ...       ...     ...  \n",
       "1242503 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.143199   93397  \n",
       "1242504 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.109665   93423  \n",
       "1242505 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.076239   93426  \n",
       "1242506 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.135851   93427  \n",
       "1242507 -0.018967  0.006284  0.026051 -0.034905 -0.019750  0.243252   93436  \n",
       "\n",
       "[1242508 rows x 23 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std_error</th>\n",
       "      <th>tstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>epq1</th>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>6.958548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dRoa1</th>\n",
       "      <td>-0.000118</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-1.454567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ioca</th>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>5.335155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ra26</th>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>2.888699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>e11</th>\n",
       "      <td>-0.000442</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>-2.048552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Re1</th>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.956194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abr1</th>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>4.594793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dRoe1</th>\n",
       "      <td>-0.000097</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>-1.174061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rnaq1</th>\n",
       "      <td>-0.000462</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>-3.529885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atoq1</th>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>6.815996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dNoa</th>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>1.609712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nsi</th>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>7.520631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dNca</th>\n",
       "      <td>-0.000566</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-5.432969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dFnl</th>\n",
       "      <td>-0.000222</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>-3.485844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean  std_error     tstat\n",
       "epq1   0.001333   0.000192  6.958548\n",
       "dRoa1 -0.000118   0.000081 -1.454567\n",
       "ioca   0.000704   0.000132  5.335155\n",
       "ra26   0.000349   0.000121  2.888699\n",
       "e11   -0.000442   0.000216 -2.048552\n",
       "Re1    0.000152   0.000159  0.956194\n",
       "Abr1   0.001243   0.000270  4.594793\n",
       "dRoe1 -0.000097   0.000082 -1.174061\n",
       "rnaq1 -0.000462   0.000131 -3.529885\n",
       "atoq1  0.000614   0.000090  6.815996\n",
       "dNoa   0.000188   0.000117  1.609712\n",
       "Nsi    0.001401   0.000186  7.520631\n",
       "dNca  -0.000566   0.000104 -5.432969\n",
       "dFnl  -0.000222   0.000064 -3.485844"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets.factor_fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assets.fact.to_csv('assets.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
